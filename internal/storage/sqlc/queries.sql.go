// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: queries.sql

package sqlc

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
	"github.com/pgvector/pgvector-go"
)

const addChannel = `-- name: AddChannel :exec
INSERT INTO channels (tg_peer_id, username, title)
VALUES ($1, $2, $3)
ON CONFLICT (tg_peer_id) WHERE tg_peer_id != 0 DO UPDATE SET username = $2, title = $3, is_active = TRUE
`

type AddChannelParams struct {
	TgPeerID int64       `json:"tg_peer_id"`
	Username pgtype.Text `json:"username"`
	Title    pgtype.Text `json:"title"`
}

func (q *Queries) AddChannel(ctx context.Context, arg AddChannelParams) error {
	_, err := q.db.Exec(ctx, addChannel, arg.TgPeerID, arg.Username, arg.Title)
	return err
}

const addChannelByID = `-- name: AddChannelByID :exec
INSERT INTO channels (tg_peer_id, username, title)
VALUES ($1, '', '')
ON CONFLICT (tg_peer_id) WHERE tg_peer_id != 0 DO UPDATE SET is_active = TRUE
`

func (q *Queries) AddChannelByID(ctx context.Context, tgPeerID int64) error {
	_, err := q.db.Exec(ctx, addChannelByID, tgPeerID)
	return err
}

const addChannelByInviteLink = `-- name: AddChannelByInviteLink :exec
INSERT INTO channels (tg_peer_id, username, title, invite_link)
VALUES (0, '', '', $1)
ON CONFLICT (invite_link) DO UPDATE SET is_active = TRUE
`

func (q *Queries) AddChannelByInviteLink(ctx context.Context, inviteLink pgtype.Text) error {
	_, err := q.db.Exec(ctx, addChannelByInviteLink, inviteLink)
	return err
}

const addChannelByUsername = `-- name: AddChannelByUsername :exec
INSERT INTO channels (tg_peer_id, username, title)
VALUES (0, $1, '')
ON CONFLICT (username) DO UPDATE SET is_active = TRUE
`

func (q *Queries) AddChannelByUsername(ctx context.Context, username pgtype.Text) error {
	_, err := q.db.Exec(ctx, addChannelByUsername, username)
	return err
}

const addFilter = `-- name: AddFilter :exec
INSERT INTO filters (type, pattern) VALUES ($1, $2)
`

type AddFilterParams struct {
	Type    string `json:"type"`
	Pattern string `json:"pattern"`
}

func (q *Queries) AddFilter(ctx context.Context, arg AddFilterParams) error {
	_, err := q.db.Exec(ctx, addFilter, arg.Type, arg.Pattern)
	return err
}

const addSettingHistory = `-- name: AddSettingHistory :exec
INSERT INTO setting_history (key, old_value, new_value, changed_by)
VALUES ($1, $2, $3, $4)
`

type AddSettingHistoryParams struct {
	Key       string      `json:"key"`
	OldValue  pgtype.Text `json:"old_value"`
	NewValue  pgtype.Text `json:"new_value"`
	ChangedBy int64       `json:"changed_by"`
}

func (q *Queries) AddSettingHistory(ctx context.Context, arg AddSettingHistoryParams) error {
	_, err := q.db.Exec(ctx, addSettingHistory,
		arg.Key,
		arg.OldValue,
		arg.NewValue,
		arg.ChangedBy,
	)
	return err
}

const addToCluster = `-- name: AddToCluster :exec
INSERT INTO cluster_items (cluster_id, item_id) VALUES ($1, $2) ON CONFLICT DO NOTHING
`

type AddToClusterParams struct {
	ClusterID pgtype.UUID `json:"cluster_id"`
	ItemID    pgtype.UUID `json:"item_id"`
}

func (q *Queries) AddToCluster(ctx context.Context, arg AddToClusterParams) error {
	_, err := q.db.Exec(ctx, addToCluster, arg.ClusterID, arg.ItemID)
	return err
}

const checkAndMarkDiscoveriesExtracted = `-- name: CheckAndMarkDiscoveriesExtracted :one
UPDATE raw_messages
SET discoveries_extracted = TRUE
WHERE channel_id = $1 AND tg_message_id = $2 AND (discoveries_extracted IS NULL OR discoveries_extracted = FALSE)
RETURNING id
`

type CheckAndMarkDiscoveriesExtractedParams struct {
	ChannelID   pgtype.UUID `json:"channel_id"`
	TgMessageID int64       `json:"tg_message_id"`
}

func (q *Queries) CheckAndMarkDiscoveriesExtracted(ctx context.Context, arg CheckAndMarkDiscoveriesExtractedParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, checkAndMarkDiscoveriesExtracted, arg.ChannelID, arg.TgMessageID)
	var id pgtype.UUID
	err := row.Scan(&id)
	return id, err
}

const checkStrictDuplicate = `-- name: CheckStrictDuplicate :one
SELECT EXISTS(
    SELECT 1 FROM raw_messages rm
    LEFT JOIN items i ON rm.id = i.raw_message_id
    WHERE rm.canonical_hash = $1 AND rm.id != $2 
    AND (rm.processed_at IS NOT NULL AND (i.status IS NULL OR i.status != 'error'))
)
`

type CheckStrictDuplicateParams struct {
	CanonicalHash string      `json:"canonical_hash"`
	ID            pgtype.UUID `json:"id"`
}

func (q *Queries) CheckStrictDuplicate(ctx context.Context, arg CheckStrictDuplicateParams) (bool, error) {
	row := q.db.QueryRow(ctx, checkStrictDuplicate, arg.CanonicalHash, arg.ID)
	var exists bool
	err := row.Scan(&exists)
	return exists, err
}

const clearDigestErrors = `-- name: ClearDigestErrors :exec
DELETE FROM digests WHERE status = 'error'
`

func (q *Queries) ClearDigestErrors(ctx context.Context) error {
	_, err := q.db.Exec(ctx, clearDigestErrors)
	return err
}

const countActiveChannels = `-- name: CountActiveChannels :one
SELECT COUNT(*) FROM channels WHERE is_active = TRUE
`

func (q *Queries) CountActiveChannels(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, countActiveChannels)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const countItemsInWindow = `-- name: CountItemsInWindow :one
SELECT COUNT(*) FROM items i
JOIN raw_messages rm ON i.raw_message_id = rm.id
WHERE rm.tg_date >= $1 AND rm.tg_date < $2
`

type CountItemsInWindowParams struct {
	TgDate   pgtype.Timestamptz `json:"tg_date"`
	TgDate_2 pgtype.Timestamptz `json:"tg_date_2"`
}

func (q *Queries) CountItemsInWindow(ctx context.Context, arg CountItemsInWindowParams) (int64, error) {
	row := q.db.QueryRow(ctx, countItemsInWindow, arg.TgDate, arg.TgDate_2)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const countReadyItems = `-- name: CountReadyItems :one
SELECT COUNT(*) FROM items WHERE status = 'ready' AND digested_at IS NULL
`

func (q *Queries) CountReadyItems(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, countReadyItems)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const countReadyItemsInWindow = `-- name: CountReadyItemsInWindow :one
SELECT COUNT(*) FROM items i
JOIN raw_messages rm ON i.raw_message_id = rm.id
WHERE rm.tg_date >= $1 AND rm.tg_date < $2 AND i.status = 'ready' AND i.digested_at IS NULL
`

type CountReadyItemsInWindowParams struct {
	TgDate   pgtype.Timestamptz `json:"tg_date"`
	TgDate_2 pgtype.Timestamptz `json:"tg_date_2"`
}

func (q *Queries) CountReadyItemsInWindow(ctx context.Context, arg CountReadyItemsInWindowParams) (int64, error) {
	row := q.db.QueryRow(ctx, countReadyItemsInWindow, arg.TgDate, arg.TgDate_2)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const countRecentlyActiveChannels = `-- name: CountRecentlyActiveChannels :one
SELECT COUNT(DISTINCT channel_id) FROM raw_messages WHERE tg_date > now() - interval '24 hours'
`

func (q *Queries) CountRecentlyActiveChannels(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, countRecentlyActiveChannels)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const createCluster = `-- name: CreateCluster :one
INSERT INTO clusters (window_start, window_end, topic)
VALUES ($1, $2, $3)
RETURNING id
`

type CreateClusterParams struct {
	WindowStart pgtype.Timestamptz `json:"window_start"`
	WindowEnd   pgtype.Timestamptz `json:"window_end"`
	Topic       pgtype.Text        `json:"topic"`
}

func (q *Queries) CreateCluster(ctx context.Context, arg CreateClusterParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, createCluster, arg.WindowStart, arg.WindowEnd, arg.Topic)
	var id pgtype.UUID
	err := row.Scan(&id)
	return id, err
}

const deactivateChannel = `-- name: DeactivateChannel :exec
UPDATE channels SET is_active = FALSE WHERE username = $1 OR '@' || username = $1 OR tg_peer_id::text = $1
`

func (q *Queries) DeactivateChannel(ctx context.Context, username pgtype.Text) error {
	_, err := q.db.Exec(ctx, deactivateChannel, username)
	return err
}

const deactivateChannelByID = `-- name: DeactivateChannelByID :exec
UPDATE channels SET is_active = FALSE WHERE id = $1
`

func (q *Queries) DeactivateChannelByID(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, deactivateChannelByID, id)
	return err
}

const deactivateFilter = `-- name: DeactivateFilter :exec
UPDATE filters SET is_active = FALSE WHERE pattern = $1
`

func (q *Queries) DeactivateFilter(ctx context.Context, pattern string) error {
	_, err := q.db.Exec(ctx, deactivateFilter, pattern)
	return err
}

const deleteClustersForWindow = `-- name: DeleteClustersForWindow :exec
DELETE FROM clusters WHERE window_start = $1 AND window_end = $2
`

type DeleteClustersForWindowParams struct {
	WindowStart pgtype.Timestamptz `json:"window_start"`
	WindowEnd   pgtype.Timestamptz `json:"window_end"`
}

func (q *Queries) DeleteClustersForWindow(ctx context.Context, arg DeleteClustersForWindowParams) error {
	_, err := q.db.Exec(ctx, deleteClustersForWindow, arg.WindowStart, arg.WindowEnd)
	return err
}

const deleteSetting = `-- name: DeleteSetting :exec
DELETE FROM settings WHERE key = $1
`

func (q *Queries) DeleteSetting(ctx context.Context, key string) error {
	_, err := q.db.Exec(ctx, deleteSetting, key)
	return err
}

const digestExists = `-- name: DigestExists :one
SELECT EXISTS(
    SELECT 1 FROM digests 
    WHERE window_start = $1 AND window_end = $2 
    AND (status = 'posted' OR (status = 'error' AND posted_at > now() - interval '1 hour'))
)
`

type DigestExistsParams struct {
	WindowStart pgtype.Timestamptz `json:"window_start"`
	WindowEnd   pgtype.Timestamptz `json:"window_end"`
}

func (q *Queries) DigestExists(ctx context.Context, arg DigestExistsParams) (bool, error) {
	row := q.db.QueryRow(ctx, digestExists, arg.WindowStart, arg.WindowEnd)
	var exists bool
	err := row.Scan(&exists)
	return exists, err
}

const extendSchedulerLock = `-- name: ExtendSchedulerLock :exec
UPDATE scheduler_locks
SET expires_at = NOW() + $3::interval
WHERE lock_name = $1 AND holder_id = $2
`

type ExtendSchedulerLockParams struct {
	LockName string          `json:"lock_name"`
	HolderID string          `json:"holder_id"`
	Column3  pgtype.Interval `json:"column_3"`
}

// Extends the lock expiry time (heartbeat)
func (q *Queries) ExtendSchedulerLock(ctx context.Context, arg ExtendSchedulerLockParams) error {
	_, err := q.db.Exec(ctx, extendSchedulerLock, arg.LockName, arg.HolderID, arg.Column3)
	return err
}

const findSimilarItem = `-- name: FindSimilarItem :one
SELECT item_id FROM embeddings
WHERE (embedding <=> $1::vector) < $2::float8
  AND created_at > $3::timestamptz
ORDER BY embedding <=> $1::vector
LIMIT 1
`

type FindSimilarItemParams struct {
	Embedding    pgvector.Vector    `json:"embedding"`
	Threshold    float64            `json:"threshold"`
	MinCreatedAt pgtype.Timestamptz `json:"min_created_at"`
}

func (q *Queries) FindSimilarItem(ctx context.Context, arg FindSimilarItemParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, findSimilarItem, arg.Embedding, arg.Threshold, arg.MinCreatedAt)
	var item_id pgtype.UUID
	err := row.Scan(&item_id)
	return item_id, err
}

const getActiveChannels = `-- name: GetActiveChannels :many
SELECT id, tg_peer_id, username, title, is_active, access_hash, invite_link, context, description, last_tg_message_id, category, tone, update_freq, relevance_threshold, importance_threshold, importance_weight, auto_weight_enabled, weight_override, auto_relevance_enabled, relevance_threshold_delta FROM channels WHERE is_active = TRUE
`

type GetActiveChannelsRow struct {
	ID                      pgtype.UUID   `json:"id"`
	TgPeerID                int64         `json:"tg_peer_id"`
	Username                pgtype.Text   `json:"username"`
	Title                   pgtype.Text   `json:"title"`
	IsActive                bool          `json:"is_active"`
	AccessHash              pgtype.Int8   `json:"access_hash"`
	InviteLink              pgtype.Text   `json:"invite_link"`
	Context                 pgtype.Text   `json:"context"`
	Description             pgtype.Text   `json:"description"`
	LastTgMessageID         int64         `json:"last_tg_message_id"`
	Category                pgtype.Text   `json:"category"`
	Tone                    pgtype.Text   `json:"tone"`
	UpdateFreq              pgtype.Text   `json:"update_freq"`
	RelevanceThreshold      pgtype.Float4 `json:"relevance_threshold"`
	ImportanceThreshold     pgtype.Float4 `json:"importance_threshold"`
	ImportanceWeight        pgtype.Float4 `json:"importance_weight"`
	AutoWeightEnabled       pgtype.Bool   `json:"auto_weight_enabled"`
	WeightOverride          pgtype.Bool   `json:"weight_override"`
	AutoRelevanceEnabled    pgtype.Bool   `json:"auto_relevance_enabled"`
	RelevanceThresholdDelta pgtype.Float4 `json:"relevance_threshold_delta"`
}

func (q *Queries) GetActiveChannels(ctx context.Context) ([]GetActiveChannelsRow, error) {
	rows, err := q.db.Query(ctx, getActiveChannels)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetActiveChannelsRow
	for rows.Next() {
		var i GetActiveChannelsRow
		if err := rows.Scan(
			&i.ID,
			&i.TgPeerID,
			&i.Username,
			&i.Title,
			&i.IsActive,
			&i.AccessHash,
			&i.InviteLink,
			&i.Context,
			&i.Description,
			&i.LastTgMessageID,
			&i.Category,
			&i.Tone,
			&i.UpdateFreq,
			&i.RelevanceThreshold,
			&i.ImportanceThreshold,
			&i.ImportanceWeight,
			&i.AutoWeightEnabled,
			&i.WeightOverride,
			&i.AutoRelevanceEnabled,
			&i.RelevanceThresholdDelta,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getActiveFilters = `-- name: GetActiveFilters :many
SELECT id, type, pattern, is_active FROM filters WHERE is_active = TRUE
`

type GetActiveFiltersRow struct {
	ID       pgtype.UUID `json:"id"`
	Type     string      `json:"type"`
	Pattern  string      `json:"pattern"`
	IsActive bool        `json:"is_active"`
}

func (q *Queries) GetActiveFilters(ctx context.Context) ([]GetActiveFiltersRow, error) {
	rows, err := q.db.Query(ctx, getActiveFilters)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetActiveFiltersRow
	for rows.Next() {
		var i GetActiveFiltersRow
		if err := rows.Scan(
			&i.ID,
			&i.Type,
			&i.Pattern,
			&i.IsActive,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getAllSettings = `-- name: GetAllSettings :many
SELECT key, value FROM settings
`

type GetAllSettingsRow struct {
	Key   string `json:"key"`
	Value []byte `json:"value"`
}

func (q *Queries) GetAllSettings(ctx context.Context) ([]GetAllSettingsRow, error) {
	rows, err := q.db.Query(ctx, getAllSettings)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetAllSettingsRow
	for rows.Next() {
		var i GetAllSettingsRow
		if err := rows.Scan(&i.Key, &i.Value); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBacklogCount = `-- name: GetBacklogCount :one
SELECT count(*) FROM raw_messages WHERE processed_at IS NULL
`

func (q *Queries) GetBacklogCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getBacklogCount)
	var count int64
	err := row.Scan(&count)
	return count, err
}

const getBulletsForDigest = `-- name: GetBulletsForDigest :many
WITH digest_item_bullets AS (
    -- Get all bullets from items in the digest (ready or duplicate)
    SELECT b.id, b.item_id, b.bullet_index, b.text, b.topic, b.relevance_score, b.importance_score, b.embedding, b.bullet_hash, b.bullet_cluster_id, b.status, b.created_at, i.raw_message_id
    FROM item_bullets b
    JOIN items i ON b.item_id = i.id
    WHERE b.item_id = ANY($1::uuid[])
      AND (b.status = 'ready' OR b.status = 'duplicate')
),
resolved AS (
    -- For duplicates, resolve to canonical bullet's text; for ready bullets, use self
    SELECT
        COALESCE(canonical.id, dib.id) as id,
        dib.item_id,  -- Keep digest item for source attribution
        COALESCE(canonical.bullet_index, dib.bullet_index) as bullet_index,
        COALESCE(canonical.text, dib.text) as text,
        COALESCE(canonical.topic, dib.topic) as topic,
        COALESCE(canonical.relevance_score, dib.relevance_score) as relevance_score,
        COALESCE(canonical.importance_score, dib.importance_score) as importance_score,
        COALESCE(canonical.bullet_hash, dib.bullet_hash) as bullet_hash,
        'ready'::text as status,
        COALESCE(canonical.created_at, dib.created_at) as created_at,
        dib.raw_message_id,
        -- canonical_id for deduplication
        COALESCE(dib.bullet_cluster_id, dib.id) as canonical_id
    FROM digest_item_bullets dib
    LEFT JOIN item_bullets canonical
        ON dib.status = 'duplicate'
        AND dib.bullet_cluster_id = canonical.id
        AND canonical.status = 'ready'
    WHERE dib.status = 'ready'
       OR canonical.id IS NOT NULL  -- Include duplicates only if canonical exists and is ready
),
source_counts AS (
    -- Count distinct items that have bullets pointing to each canonical bullet
    SELECT bullet_cluster_id, COUNT(DISTINCT item_id) as source_count
    FROM item_bullets
    WHERE bullet_cluster_id IS NOT NULL
    GROUP BY bullet_cluster_id
)
SELECT id, item_id, bullet_index, text, topic, relevance_score, importance_score, bullet_hash, status, created_at, source_channel, source_channel_title, tg_date, source_count FROM (
    SELECT DISTINCT ON (r.canonical_id)
        r.id, r.item_id, r.bullet_index, r.text, r.topic, r.relevance_score,
        r.importance_score, r.bullet_hash, r.status, r.created_at,
        c.username as source_channel, c.title as source_channel_title, rm.tg_date,
        COALESCE(sc.source_count, 1)::int as source_count
    FROM resolved r
    JOIN raw_messages rm ON r.raw_message_id = rm.id
    JOIN channels c ON rm.channel_id = c.id
    LEFT JOIN source_counts sc ON sc.bullet_cluster_id = r.canonical_id
    ORDER BY r.canonical_id, r.importance_score DESC
) deduped
ORDER BY importance_score DESC
`

type GetBulletsForDigestRow struct {
	ID                 pgtype.UUID        `json:"id"`
	ItemID             pgtype.UUID        `json:"item_id"`
	BulletIndex        int32              `json:"bullet_index"`
	Text               string             `json:"text"`
	Topic              pgtype.Text        `json:"topic"`
	RelevanceScore     pgtype.Float4      `json:"relevance_score"`
	ImportanceScore    pgtype.Float4      `json:"importance_score"`
	BulletHash         pgtype.Text        `json:"bullet_hash"`
	Status             string             `json:"status"`
	CreatedAt          pgtype.Timestamptz `json:"created_at"`
	SourceChannel      pgtype.Text        `json:"source_channel"`
	SourceChannelTitle pgtype.Text        `json:"source_channel_title"`
	TgDate             pgtype.Timestamptz `json:"tg_date"`
	SourceCount        int32              `json:"source_count"`
}

// Handles both canonical bullets and duplicate bullets whose canonical may be outside the digest.
// For duplicates, joins to canonical bullet to get text while keeping digest item's source info.
func (q *Queries) GetBulletsForDigest(ctx context.Context, dollar_1 []pgtype.UUID) ([]GetBulletsForDigestRow, error) {
	rows, err := q.db.Query(ctx, getBulletsForDigest, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetBulletsForDigestRow
	for rows.Next() {
		var i GetBulletsForDigestRow
		if err := rows.Scan(
			&i.ID,
			&i.ItemID,
			&i.BulletIndex,
			&i.Text,
			&i.Topic,
			&i.RelevanceScore,
			&i.ImportanceScore,
			&i.BulletHash,
			&i.Status,
			&i.CreatedAt,
			&i.SourceChannel,
			&i.SourceChannelTitle,
			&i.TgDate,
			&i.SourceCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBulletsForItem = `-- name: GetBulletsForItem :many
SELECT id, item_id, bullet_index, text, topic, relevance_score, importance_score, embedding, bullet_hash, bullet_cluster_id, status, created_at FROM item_bullets WHERE item_id = $1 ORDER BY bullet_index
`

func (q *Queries) GetBulletsForItem(ctx context.Context, itemID pgtype.UUID) ([]ItemBullet, error) {
	rows, err := q.db.Query(ctx, getBulletsForItem, itemID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []ItemBullet
	for rows.Next() {
		var i ItemBullet
		if err := rows.Scan(
			&i.ID,
			&i.ItemID,
			&i.BulletIndex,
			&i.Text,
			&i.Topic,
			&i.RelevanceScore,
			&i.ImportanceScore,
			&i.Embedding,
			&i.BulletHash,
			&i.BulletClusterID,
			&i.Status,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getBulletsForItems = `-- name: GetBulletsForItems :many
SELECT id, item_id, bullet_index, text, topic, relevance_score, importance_score, embedding, bullet_hash, bullet_cluster_id, status, created_at FROM item_bullets WHERE item_id = ANY($1::uuid[]) AND status = 'ready' ORDER BY importance_score DESC
`

func (q *Queries) GetBulletsForItems(ctx context.Context, dollar_1 []pgtype.UUID) ([]ItemBullet, error) {
	rows, err := q.db.Query(ctx, getBulletsForItems, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []ItemBullet
	for rows.Next() {
		var i ItemBullet
		if err := rows.Scan(
			&i.ID,
			&i.ItemID,
			&i.BulletIndex,
			&i.Text,
			&i.Topic,
			&i.RelevanceScore,
			&i.ImportanceScore,
			&i.Embedding,
			&i.BulletHash,
			&i.BulletClusterID,
			&i.Status,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getChannelByID = `-- name: GetChannelByID :one
SELECT id, tg_peer_id, username, invite_link, is_active FROM channels WHERE id = $1
`

type GetChannelByIDRow struct {
	ID         pgtype.UUID `json:"id"`
	TgPeerID   int64       `json:"tg_peer_id"`
	Username   pgtype.Text `json:"username"`
	InviteLink pgtype.Text `json:"invite_link"`
	IsActive   bool        `json:"is_active"`
}

func (q *Queries) GetChannelByID(ctx context.Context, id pgtype.UUID) (GetChannelByIDRow, error) {
	row := q.db.QueryRow(ctx, getChannelByID, id)
	var i GetChannelByIDRow
	err := row.Scan(
		&i.ID,
		&i.TgPeerID,
		&i.Username,
		&i.InviteLink,
		&i.IsActive,
	)
	return i, err
}

const getChannelByPeerID = `-- name: GetChannelByPeerID :one
SELECT id, tg_peer_id, username, title, is_active, added_at, added_by_tg_user, access_hash, invite_link, context, description, last_tg_message_id, category, tone, update_freq, relevance_threshold, importance_threshold, importance_weight, auto_weight_enabled, weight_override, weight_override_reason, weight_updated_at, weight_updated_by, auto_relevance_enabled, relevance_threshold_delta FROM channels WHERE tg_peer_id = $1
`

func (q *Queries) GetChannelByPeerID(ctx context.Context, tgPeerID int64) (Channel, error) {
	row := q.db.QueryRow(ctx, getChannelByPeerID, tgPeerID)
	var i Channel
	err := row.Scan(
		&i.ID,
		&i.TgPeerID,
		&i.Username,
		&i.Title,
		&i.IsActive,
		&i.AddedAt,
		&i.AddedByTgUser,
		&i.AccessHash,
		&i.InviteLink,
		&i.Context,
		&i.Description,
		&i.LastTgMessageID,
		&i.Category,
		&i.Tone,
		&i.UpdateFreq,
		&i.RelevanceThreshold,
		&i.ImportanceThreshold,
		&i.ImportanceWeight,
		&i.AutoWeightEnabled,
		&i.WeightOverride,
		&i.WeightOverrideReason,
		&i.WeightUpdatedAt,
		&i.WeightUpdatedBy,
		&i.AutoRelevanceEnabled,
		&i.RelevanceThresholdDelta,
	)
	return i, err
}

const getChannelStats = `-- name: GetChannelStats :many
SELECT rm.channel_id, 
       (COUNT(i.id) FILTER (WHERE i.status = 'ready')::float4 * 100.0 / NULLIF(COUNT(rm.id), 0)::float4)::float4 as conversion_rate,
       COALESCE(AVG(i.relevance_score) FILTER (WHERE i.status = 'ready'), 0)::float4 as avg_relevance,
       COALESCE(STDDEV(i.relevance_score) FILTER (WHERE i.status = 'ready'), 0)::float4 as stddev_relevance,
       COALESCE(AVG(i.importance_score) FILTER (WHERE i.status = 'ready'), 0)::float4 as avg_importance,
       COALESCE(STDDEV(i.importance_score) FILTER (WHERE i.status = 'ready'), 0)::float4 as stddev_importance
FROM raw_messages rm
LEFT JOIN items i ON rm.id = i.raw_message_id
WHERE rm.tg_date > now() - interval '7 days'
GROUP BY rm.channel_id
`

type GetChannelStatsRow struct {
	ChannelID        pgtype.UUID `json:"channel_id"`
	ConversionRate   float32     `json:"conversion_rate"`
	AvgRelevance     float32     `json:"avg_relevance"`
	StddevRelevance  float32     `json:"stddev_relevance"`
	AvgImportance    float32     `json:"avg_importance"`
	StddevImportance float32     `json:"stddev_importance"`
}

func (q *Queries) GetChannelStats(ctx context.Context) ([]GetChannelStatsRow, error) {
	rows, err := q.db.Query(ctx, getChannelStats)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetChannelStatsRow
	for rows.Next() {
		var i GetChannelStatsRow
		if err := rows.Scan(
			&i.ChannelID,
			&i.ConversionRate,
			&i.AvgRelevance,
			&i.StddevRelevance,
			&i.AvgImportance,
			&i.StddevImportance,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getChannelStatsForPeriod = `-- name: GetChannelStatsForPeriod :many
SELECT cs.id, cs.channel_id, cs.period_start, cs.period_end, cs.messages_received, cs.items_created, cs.items_digested, cs.avg_importance, cs.avg_relevance, cs.created_at, cs.updated_at, c.username, c.title
FROM channel_stats cs
JOIN channels c ON cs.channel_id = c.id
WHERE cs.period_start >= $1 AND cs.period_end <= $2
`

type GetChannelStatsForPeriodParams struct {
	PeriodStart pgtype.Date `json:"period_start"`
	PeriodEnd   pgtype.Date `json:"period_end"`
}

type GetChannelStatsForPeriodRow struct {
	ID               int32              `json:"id"`
	ChannelID        pgtype.UUID        `json:"channel_id"`
	PeriodStart      pgtype.Date        `json:"period_start"`
	PeriodEnd        pgtype.Date        `json:"period_end"`
	MessagesReceived pgtype.Int4        `json:"messages_received"`
	ItemsCreated     pgtype.Int4        `json:"items_created"`
	ItemsDigested    pgtype.Int4        `json:"items_digested"`
	AvgImportance    pgtype.Float8      `json:"avg_importance"`
	AvgRelevance     pgtype.Float8      `json:"avg_relevance"`
	CreatedAt        pgtype.Timestamptz `json:"created_at"`
	UpdatedAt        pgtype.Timestamptz `json:"updated_at"`
	Username         pgtype.Text        `json:"username"`
	Title            pgtype.Text        `json:"title"`
}

func (q *Queries) GetChannelStatsForPeriod(ctx context.Context, arg GetChannelStatsForPeriodParams) ([]GetChannelStatsForPeriodRow, error) {
	rows, err := q.db.Query(ctx, getChannelStatsForPeriod, arg.PeriodStart, arg.PeriodEnd)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetChannelStatsForPeriodRow
	for rows.Next() {
		var i GetChannelStatsForPeriodRow
		if err := rows.Scan(
			&i.ID,
			&i.ChannelID,
			&i.PeriodStart,
			&i.PeriodEnd,
			&i.MessagesReceived,
			&i.ItemsCreated,
			&i.ItemsDigested,
			&i.AvgImportance,
			&i.AvgRelevance,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.Username,
			&i.Title,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getChannelStatsForWindow = `-- name: GetChannelStatsForWindow :many
SELECT
    c.id as channel_id,
    COUNT(DISTINCT rm.id) as messages_received,
    COUNT(DISTINCT CASE WHEN i.status = 'ready' OR i.status = 'digested' THEN i.id END) as items_created,
    COUNT(DISTINCT CASE WHEN i.status = 'digested' THEN i.id END) as items_digested,
    COALESCE(AVG(CASE WHEN i.status IN ('ready', 'digested') THEN i.importance_score END), 0) as avg_importance,
    COALESCE(AVG(CASE WHEN i.status IN ('ready', 'digested') THEN i.relevance_score END), 0) as avg_relevance
FROM channels c
LEFT JOIN raw_messages rm ON rm.channel_id = c.id AND rm.tg_date >= $1 AND rm.tg_date < $2
LEFT JOIN items i ON i.raw_message_id = rm.id
WHERE c.is_active = TRUE
GROUP BY c.id
HAVING COUNT(DISTINCT rm.id) > 0
`

type GetChannelStatsForWindowParams struct {
	TgDate   pgtype.Timestamptz `json:"tg_date"`
	TgDate_2 pgtype.Timestamptz `json:"tg_date_2"`
}

type GetChannelStatsForWindowRow struct {
	ChannelID        pgtype.UUID `json:"channel_id"`
	MessagesReceived int64       `json:"messages_received"`
	ItemsCreated     int64       `json:"items_created"`
	ItemsDigested    int64       `json:"items_digested"`
	AvgImportance    interface{} `json:"avg_importance"`
	AvgRelevance     interface{} `json:"avg_relevance"`
}

func (q *Queries) GetChannelStatsForWindow(ctx context.Context, arg GetChannelStatsForWindowParams) ([]GetChannelStatsForWindowRow, error) {
	rows, err := q.db.Query(ctx, getChannelStatsForWindow, arg.TgDate, arg.TgDate_2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetChannelStatsForWindowRow
	for rows.Next() {
		var i GetChannelStatsForWindowRow
		if err := rows.Scan(
			&i.ChannelID,
			&i.MessagesReceived,
			&i.ItemsCreated,
			&i.ItemsDigested,
			&i.AvgImportance,
			&i.AvgRelevance,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getChannelStatsRolling = `-- name: GetChannelStatsRolling :one
SELECT
    COALESCE(SUM(messages_received), 0)::int as total_messages,
    COALESCE(SUM(items_created), 0)::int as total_items_created,
    COALESCE(SUM(items_digested), 0)::int as total_items_digested,
    COALESCE(AVG(avg_importance), 0)::float as avg_importance,
    COALESCE(AVG(avg_relevance), 0)::float as avg_relevance
FROM channel_stats
WHERE channel_id = $1 AND period_start >= $2
`

type GetChannelStatsRollingParams struct {
	ChannelID   pgtype.UUID `json:"channel_id"`
	PeriodStart pgtype.Date `json:"period_start"`
}

type GetChannelStatsRollingRow struct {
	TotalMessages      int32   `json:"total_messages"`
	TotalItemsCreated  int32   `json:"total_items_created"`
	TotalItemsDigested int32   `json:"total_items_digested"`
	AvgImportance      float64 `json:"avg_importance"`
	AvgRelevance       float64 `json:"avg_relevance"`
}

func (q *Queries) GetChannelStatsRolling(ctx context.Context, arg GetChannelStatsRollingParams) (GetChannelStatsRollingRow, error) {
	row := q.db.QueryRow(ctx, getChannelStatsRolling, arg.ChannelID, arg.PeriodStart)
	var i GetChannelStatsRollingRow
	err := row.Scan(
		&i.TotalMessages,
		&i.TotalItemsCreated,
		&i.TotalItemsDigested,
		&i.AvgImportance,
		&i.AvgRelevance,
	)
	return i, err
}

const getChannelWeight = `-- name: GetChannelWeight :one
SELECT username, title, importance_weight, auto_weight_enabled, weight_override, weight_override_reason, weight_updated_at
FROM channels
WHERE username = $1 OR '@' || username = $1 OR tg_peer_id::text = $1
`

type GetChannelWeightRow struct {
	Username             pgtype.Text        `json:"username"`
	Title                pgtype.Text        `json:"title"`
	ImportanceWeight     pgtype.Float4      `json:"importance_weight"`
	AutoWeightEnabled    pgtype.Bool        `json:"auto_weight_enabled"`
	WeightOverride       pgtype.Bool        `json:"weight_override"`
	WeightOverrideReason pgtype.Text        `json:"weight_override_reason"`
	WeightUpdatedAt      pgtype.Timestamptz `json:"weight_updated_at"`
}

func (q *Queries) GetChannelWeight(ctx context.Context, username pgtype.Text) (GetChannelWeightRow, error) {
	row := q.db.QueryRow(ctx, getChannelWeight, username)
	var i GetChannelWeightRow
	err := row.Scan(
		&i.Username,
		&i.Title,
		&i.ImportanceWeight,
		&i.AutoWeightEnabled,
		&i.WeightOverride,
		&i.WeightOverrideReason,
		&i.WeightUpdatedAt,
	)
	return i, err
}

const getChannelsForAutoWeight = `-- name: GetChannelsForAutoWeight :many
SELECT id, username, title, importance_weight, auto_weight_enabled, weight_override
FROM channels
WHERE is_active = TRUE AND auto_weight_enabled = TRUE AND weight_override = FALSE
`

type GetChannelsForAutoWeightRow struct {
	ID                pgtype.UUID   `json:"id"`
	Username          pgtype.Text   `json:"username"`
	Title             pgtype.Text   `json:"title"`
	ImportanceWeight  pgtype.Float4 `json:"importance_weight"`
	AutoWeightEnabled pgtype.Bool   `json:"auto_weight_enabled"`
	WeightOverride    pgtype.Bool   `json:"weight_override"`
}

func (q *Queries) GetChannelsForAutoWeight(ctx context.Context) ([]GetChannelsForAutoWeightRow, error) {
	rows, err := q.db.Query(ctx, getChannelsForAutoWeight)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetChannelsForAutoWeightRow
	for rows.Next() {
		var i GetChannelsForAutoWeightRow
		if err := rows.Scan(
			&i.ID,
			&i.Username,
			&i.Title,
			&i.ImportanceWeight,
			&i.AutoWeightEnabled,
			&i.WeightOverride,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getClusterSummaryCache = `-- name: GetClusterSummaryCache :many

SELECT cluster_fingerprint,
       item_ids,
       summary,
       updated_at
FROM cluster_summary_cache
WHERE digest_language = $1
  AND updated_at >= $2
`

type GetClusterSummaryCacheParams struct {
	DigestLanguage string             `json:"digest_language"`
	UpdatedAt      pgtype.Timestamptz `json:"updated_at"`
}

type GetClusterSummaryCacheRow struct {
	ClusterFingerprint string             `json:"cluster_fingerprint"`
	ItemIds            []byte             `json:"item_ids"`
	Summary            string             `json:"summary"`
	UpdatedAt          pgtype.Timestamptz `json:"updated_at"`
}

// Cluster Summary Cache queries
func (q *Queries) GetClusterSummaryCache(ctx context.Context, arg GetClusterSummaryCacheParams) ([]GetClusterSummaryCacheRow, error) {
	rows, err := q.db.Query(ctx, getClusterSummaryCache, arg.DigestLanguage, arg.UpdatedAt)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetClusterSummaryCacheRow
	for rows.Next() {
		var i GetClusterSummaryCacheRow
		if err := rows.Scan(
			&i.ClusterFingerprint,
			&i.ItemIds,
			&i.Summary,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getClusterSummaryCacheEntry = `-- name: GetClusterSummaryCacheEntry :one
SELECT cluster_fingerprint,
       item_ids,
       summary,
       updated_at
FROM cluster_summary_cache
WHERE digest_language = $1 AND cluster_fingerprint = $2
`

type GetClusterSummaryCacheEntryParams struct {
	DigestLanguage     string `json:"digest_language"`
	ClusterFingerprint string `json:"cluster_fingerprint"`
}

type GetClusterSummaryCacheEntryRow struct {
	ClusterFingerprint string             `json:"cluster_fingerprint"`
	ItemIds            []byte             `json:"item_ids"`
	Summary            string             `json:"summary"`
	UpdatedAt          pgtype.Timestamptz `json:"updated_at"`
}

func (q *Queries) GetClusterSummaryCacheEntry(ctx context.Context, arg GetClusterSummaryCacheEntryParams) (GetClusterSummaryCacheEntryRow, error) {
	row := q.db.QueryRow(ctx, getClusterSummaryCacheEntry, arg.DigestLanguage, arg.ClusterFingerprint)
	var i GetClusterSummaryCacheEntryRow
	err := row.Scan(
		&i.ClusterFingerprint,
		&i.ItemIds,
		&i.Summary,
		&i.UpdatedAt,
	)
	return i, err
}

const getClustersForWindow = `-- name: GetClustersForWindow :many
SELECT c.id as cluster_id, c.topic as cluster_topic, i.id as item_id, i.summary as item_summary, ch.username as channel_username, ch.tg_peer_id as channel_peer_id, rm.tg_message_id as rm_msg_id
FROM clusters c
JOIN cluster_items ci ON c.id = ci.cluster_id
JOIN items i ON ci.item_id = i.id
JOIN raw_messages rm ON i.raw_message_id = rm.id
JOIN channels ch ON rm.channel_id = ch.id
WHERE c.window_start = $1 AND c.window_end = $2
ORDER BY c.id
`

type GetClustersForWindowParams struct {
	WindowStart pgtype.Timestamptz `json:"window_start"`
	WindowEnd   pgtype.Timestamptz `json:"window_end"`
}

type GetClustersForWindowRow struct {
	ClusterID       pgtype.UUID `json:"cluster_id"`
	ClusterTopic    pgtype.Text `json:"cluster_topic"`
	ItemID          pgtype.UUID `json:"item_id"`
	ItemSummary     pgtype.Text `json:"item_summary"`
	ChannelUsername pgtype.Text `json:"channel_username"`
	ChannelPeerID   int64       `json:"channel_peer_id"`
	RmMsgID         int64       `json:"rm_msg_id"`
}

func (q *Queries) GetClustersForWindow(ctx context.Context, arg GetClustersForWindowParams) ([]GetClustersForWindowRow, error) {
	rows, err := q.db.Query(ctx, getClustersForWindow, arg.WindowStart, arg.WindowEnd)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetClustersForWindowRow
	for rows.Next() {
		var i GetClustersForWindowRow
		if err := rows.Scan(
			&i.ClusterID,
			&i.ClusterTopic,
			&i.ItemID,
			&i.ItemSummary,
			&i.ChannelUsername,
			&i.ChannelPeerID,
			&i.RmMsgID,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDigestCoverImage = `-- name: GetDigestCoverImage :one
SELECT rm.media_data
FROM items i
JOIN raw_messages rm ON i.raw_message_id = rm.id
WHERE rm.tg_date >= $1 AND rm.tg_date < $2
  AND i.status = 'ready'
  AND i.importance_score >= $3
  AND rm.media_data IS NOT NULL
  AND length(rm.media_data) > 0
ORDER BY i.importance_score DESC, i.relevance_score DESC
LIMIT 1
`

type GetDigestCoverImageParams struct {
	TgDate          pgtype.Timestamptz `json:"tg_date"`
	TgDate_2        pgtype.Timestamptz `json:"tg_date_2"`
	ImportanceScore float32            `json:"importance_score"`
}

func (q *Queries) GetDigestCoverImage(ctx context.Context, arg GetDigestCoverImageParams) ([]byte, error) {
	row := q.db.QueryRow(ctx, getDigestCoverImage, arg.TgDate, arg.TgDate_2, arg.ImportanceScore)
	var media_data []byte
	err := row.Scan(&media_data)
	return media_data, err
}

const getDiscoveriesNeedingResolution = `-- name: GetDiscoveriesNeedingResolution :many
SELECT id, tg_peer_id, COALESCE(access_hash, 0) as access_hash
FROM discovered_channels
WHERE status = 'pending'
  AND tg_peer_id != 0
  AND (title IS NULL OR title = '')
  AND (username IS NULL OR username = '')
  AND (resolution_attempts IS NULL OR resolution_attempts < 3)
  AND (last_resolution_attempt IS NULL OR last_resolution_attempt < now() - interval '1 hour')
ORDER BY discovery_count DESC
LIMIT $1
`

type GetDiscoveriesNeedingResolutionRow struct {
	ID         pgtype.UUID `json:"id"`
	TgPeerID   pgtype.Int8 `json:"tg_peer_id"`
	AccessHash int64       `json:"access_hash"`
}

func (q *Queries) GetDiscoveriesNeedingResolution(ctx context.Context, limit int32) ([]GetDiscoveriesNeedingResolutionRow, error) {
	rows, err := q.db.Query(ctx, getDiscoveriesNeedingResolution, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetDiscoveriesNeedingResolutionRow
	for rows.Next() {
		var i GetDiscoveriesNeedingResolutionRow
		if err := rows.Scan(&i.ID, &i.TgPeerID, &i.AccessHash); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDiscoveryByUsername = `-- name: GetDiscoveryByUsername :one
SELECT dc.id, dc.username, dc.tg_peer_id, dc.invite_link, dc.title, dc.description, dc.source_type,
       dc.discovery_count, dc.first_seen_at, dc.last_seen_at, dc.max_views, dc.max_forwards, dc.engagement_score,
       dc.status, dc.matched_channel_id
FROM discovered_channels dc
WHERE lower(dc.username) = lower($1) OR lower('@' || dc.username) = lower($1)
ORDER BY dc.last_seen_at DESC
LIMIT 1
`

type GetDiscoveryByUsernameRow struct {
	ID               pgtype.UUID        `json:"id"`
	Username         pgtype.Text        `json:"username"`
	TgPeerID         pgtype.Int8        `json:"tg_peer_id"`
	InviteLink       pgtype.Text        `json:"invite_link"`
	Title            pgtype.Text        `json:"title"`
	Description      pgtype.Text        `json:"description"`
	SourceType       string             `json:"source_type"`
	DiscoveryCount   int32              `json:"discovery_count"`
	FirstSeenAt      pgtype.Timestamptz `json:"first_seen_at"`
	LastSeenAt       pgtype.Timestamptz `json:"last_seen_at"`
	MaxViews         pgtype.Int4        `json:"max_views"`
	MaxForwards      pgtype.Int4        `json:"max_forwards"`
	EngagementScore  pgtype.Float4      `json:"engagement_score"`
	Status           string             `json:"status"`
	MatchedChannelID pgtype.UUID        `json:"matched_channel_id"`
}

func (q *Queries) GetDiscoveryByUsername(ctx context.Context, lower string) (GetDiscoveryByUsernameRow, error) {
	row := q.db.QueryRow(ctx, getDiscoveryByUsername, lower)
	var i GetDiscoveryByUsernameRow
	err := row.Scan(
		&i.ID,
		&i.Username,
		&i.TgPeerID,
		&i.InviteLink,
		&i.Title,
		&i.Description,
		&i.SourceType,
		&i.DiscoveryCount,
		&i.FirstSeenAt,
		&i.LastSeenAt,
		&i.MaxViews,
		&i.MaxForwards,
		&i.EngagementScore,
		&i.Status,
		&i.MatchedChannelID,
	)
	return i, err
}

const getDiscoveryFilterStats = `-- name: GetDiscoveryFilterStats :one
SELECT
    COUNT(*) FILTER (
        WHERE status = 'pending'
          AND matched_channel_id IS NOT NULL
    ) as matched_channel_id_count,
    COUNT(*) FILTER (
        WHERE status = 'pending'
          AND matched_channel_id IS NULL
          AND username IS NOT NULL AND username != ''
          AND (discovery_count < $1 OR COALESCE(engagement_score, 0) < $2)
    ) as below_threshold_count,
    COUNT(*) FILTER (
        WHERE status = 'pending'
          AND matched_channel_id IS NULL
          AND username IS NOT NULL AND username != ''
          AND discovery_count >= $1
          AND COALESCE(engagement_score, 0) >= $2
          AND EXISTS (
            SELECT 1
            FROM channels c
            WHERE c.is_active = TRUE AND (
              (c.username != '' AND lower(c.username) = lower(discovered_channels.username)) OR
              (c.username != '' AND lower('@' || c.username) = lower(discovered_channels.username)) OR
              (c.tg_peer_id = discovered_channels.tg_peer_id AND discovered_channels.tg_peer_id != 0 AND c.tg_peer_id != 0) OR
              (c.invite_link = discovered_channels.invite_link AND discovered_channels.invite_link != '' AND c.invite_link != '')
            )
          )
    ) as already_tracked_count
FROM discovered_channels
`

type GetDiscoveryFilterStatsParams struct {
	DiscoveryCount  int32         `json:"discovery_count"`
	EngagementScore pgtype.Float4 `json:"engagement_score"`
}

type GetDiscoveryFilterStatsRow struct {
	MatchedChannelIDCount int64 `json:"matched_channel_id_count"`
	BelowThresholdCount   int64 `json:"below_threshold_count"`
	AlreadyTrackedCount   int64 `json:"already_tracked_count"`
}

func (q *Queries) GetDiscoveryFilterStats(ctx context.Context, arg GetDiscoveryFilterStatsParams) (GetDiscoveryFilterStatsRow, error) {
	row := q.db.QueryRow(ctx, getDiscoveryFilterStats, arg.DiscoveryCount, arg.EngagementScore)
	var i GetDiscoveryFilterStatsRow
	err := row.Scan(&i.MatchedChannelIDCount, &i.BelowThresholdCount, &i.AlreadyTrackedCount)
	return i, err
}

const getDiscoveryStats = `-- name: GetDiscoveryStats :one
SELECT
    COUNT(*) FILTER (WHERE status = 'pending' AND username IS NOT NULL AND username != '') as pending_count,
    COUNT(*) FILTER (WHERE status = 'pending' AND (username IS NULL OR username = '')) as unresolved_count,
    COUNT(*) FILTER (WHERE status = 'approved') as approved_count,
    COUNT(*) FILTER (WHERE status = 'rejected') as rejected_count,
    COUNT(*) FILTER (WHERE status = 'added') as added_count,
    COUNT(*) as total_count,
    COALESCE(SUM(discovery_count), 0) as total_discoveries
FROM discovered_channels
`

type GetDiscoveryStatsRow struct {
	PendingCount     int64       `json:"pending_count"`
	UnresolvedCount  int64       `json:"unresolved_count"`
	ApprovedCount    int64       `json:"approved_count"`
	RejectedCount    int64       `json:"rejected_count"`
	AddedCount       int64       `json:"added_count"`
	TotalCount       int64       `json:"total_count"`
	TotalDiscoveries interface{} `json:"total_discoveries"`
}

func (q *Queries) GetDiscoveryStats(ctx context.Context) (GetDiscoveryStatsRow, error) {
	row := q.db.QueryRow(ctx, getDiscoveryStats)
	var i GetDiscoveryStatsRow
	err := row.Scan(
		&i.PendingCount,
		&i.UnresolvedCount,
		&i.ApprovedCount,
		&i.RejectedCount,
		&i.AddedCount,
		&i.TotalCount,
		&i.TotalDiscoveries,
	)
	return i, err
}

const getDropReasonStats = `-- name: GetDropReasonStats :many
SELECT d.reason, COUNT(*)::int as count
FROM raw_message_drop_log d
JOIN raw_messages rm ON d.raw_message_id = rm.id
WHERE rm.tg_date >= $1
GROUP BY d.reason
ORDER BY COUNT(*) DESC
LIMIT $2
`

type GetDropReasonStatsParams struct {
	TgDate pgtype.Timestamptz `json:"tg_date"`
	Limit  int32              `json:"limit"`
}

type GetDropReasonStatsRow struct {
	Reason string `json:"reason"`
	Count  int32  `json:"count"`
}

func (q *Queries) GetDropReasonStats(ctx context.Context, arg GetDropReasonStatsParams) ([]GetDropReasonStatsRow, error) {
	rows, err := q.db.Query(ctx, getDropReasonStats, arg.TgDate, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetDropReasonStatsRow
	for rows.Next() {
		var i GetDropReasonStatsRow
		if err := rows.Scan(&i.Reason, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getEnrichmentErrors = `-- name: GetEnrichmentErrors :many
SELECT id, item_id, error_message, attempt_count, created_at
FROM enrichment_queue
WHERE status = 'error'
ORDER BY created_at DESC
LIMIT $1
`

type GetEnrichmentErrorsRow struct {
	ID           pgtype.UUID        `json:"id"`
	ItemID       pgtype.UUID        `json:"item_id"`
	ErrorMessage pgtype.Text        `json:"error_message"`
	AttemptCount int32              `json:"attempt_count"`
	CreatedAt    pgtype.Timestamptz `json:"created_at"`
}

func (q *Queries) GetEnrichmentErrors(ctx context.Context, limit int32) ([]GetEnrichmentErrorsRow, error) {
	rows, err := q.db.Query(ctx, getEnrichmentErrors, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetEnrichmentErrorsRow
	for rows.Next() {
		var i GetEnrichmentErrorsRow
		if err := rows.Scan(
			&i.ID,
			&i.ItemID,
			&i.ErrorMessage,
			&i.AttemptCount,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getEnrichmentQueueStats = `-- name: GetEnrichmentQueueStats :many
SELECT status, COUNT(*) as count FROM enrichment_queue GROUP BY status
`

type GetEnrichmentQueueStatsRow struct {
	Status string `json:"status"`
	Count  int64  `json:"count"`
}

func (q *Queries) GetEnrichmentQueueStats(ctx context.Context) ([]GetEnrichmentQueueStatsRow, error) {
	rows, err := q.db.Query(ctx, getEnrichmentQueueStats)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetEnrichmentQueueStatsRow
	for rows.Next() {
		var i GetEnrichmentQueueStatsRow
		if err := rows.Scan(&i.Status, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getInviteLinkDiscoveriesNeedingResolution = `-- name: GetInviteLinkDiscoveriesNeedingResolution :many
SELECT id, invite_link
FROM discovered_channels
WHERE status = 'pending'
  AND invite_link IS NOT NULL AND invite_link != ''
  AND (title IS NULL OR title = '')
  AND (resolution_attempts IS NULL OR resolution_attempts < 3)
  AND (last_resolution_attempt IS NULL OR last_resolution_attempt < now() - interval '1 hour')
ORDER BY discovery_count DESC
LIMIT $1
`

type GetInviteLinkDiscoveriesNeedingResolutionRow struct {
	ID         pgtype.UUID `json:"id"`
	InviteLink pgtype.Text `json:"invite_link"`
}

func (q *Queries) GetInviteLinkDiscoveriesNeedingResolution(ctx context.Context, limit int32) ([]GetInviteLinkDiscoveriesNeedingResolutionRow, error) {
	rows, err := q.db.Query(ctx, getInviteLinkDiscoveriesNeedingResolution, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetInviteLinkDiscoveriesNeedingResolutionRow
	for rows.Next() {
		var i GetInviteLinkDiscoveriesNeedingResolutionRow
		if err := rows.Scan(&i.ID, &i.InviteLink); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getItemByCanonicalURL = `-- name: GetItemByCanonicalURL :one
SELECT i.id, i.summary, i.topic, i.language
FROM items i
JOIN message_links ml ON ml.raw_message_id = i.raw_message_id
JOIN link_cache lc ON lc.id = ml.link_cache_id
WHERE lc.canonical_url = $1
  AND i.raw_message_id != $2
  AND i.status = 'ready'
ORDER BY i.importance_score DESC
LIMIT 1
`

type GetItemByCanonicalURLParams struct {
	CanonicalUrl pgtype.Text `json:"canonical_url"`
	RawMessageID pgtype.UUID `json:"raw_message_id"`
}

type GetItemByCanonicalURLRow struct {
	ID       pgtype.UUID `json:"id"`
	Summary  pgtype.Text `json:"summary"`
	Topic    pgtype.Text `json:"topic"`
	Language pgtype.Text `json:"language"`
}

func (q *Queries) GetItemByCanonicalURL(ctx context.Context, arg GetItemByCanonicalURLParams) (GetItemByCanonicalURLRow, error) {
	row := q.db.QueryRow(ctx, getItemByCanonicalURL, arg.CanonicalUrl, arg.RawMessageID)
	var i GetItemByCanonicalURLRow
	err := row.Scan(
		&i.ID,
		&i.Summary,
		&i.Topic,
		&i.Language,
	)
	return i, err
}

const getItemByID = `-- name: GetItemByID :one
SELECT id, raw_message_id, relevance_score, importance_score, topic, summary, language, status, error_json, created_at, first_seen_at, digested_at
FROM items WHERE id = $1
`

type GetItemByIDRow struct {
	ID              pgtype.UUID        `json:"id"`
	RawMessageID    pgtype.UUID        `json:"raw_message_id"`
	RelevanceScore  float32            `json:"relevance_score"`
	ImportanceScore float32            `json:"importance_score"`
	Topic           pgtype.Text        `json:"topic"`
	Summary         pgtype.Text        `json:"summary"`
	Language        pgtype.Text        `json:"language"`
	Status          string             `json:"status"`
	ErrorJson       []byte             `json:"error_json"`
	CreatedAt       pgtype.Timestamptz `json:"created_at"`
	FirstSeenAt     pgtype.Timestamptz `json:"first_seen_at"`
	DigestedAt      pgtype.Timestamptz `json:"digested_at"`
}

func (q *Queries) GetItemByID(ctx context.Context, id pgtype.UUID) (GetItemByIDRow, error) {
	row := q.db.QueryRow(ctx, getItemByID, id)
	var i GetItemByIDRow
	err := row.Scan(
		&i.ID,
		&i.RawMessageID,
		&i.RelevanceScore,
		&i.ImportanceScore,
		&i.Topic,
		&i.Summary,
		&i.Language,
		&i.Status,
		&i.ErrorJson,
		&i.CreatedAt,
		&i.FirstSeenAt,
		&i.DigestedAt,
	)
	return i, err
}

const getItemEmbedding = `-- name: GetItemEmbedding :one
SELECT embedding::text FROM embeddings WHERE item_id = $1
`

func (q *Queries) GetItemEmbedding(ctx context.Context, itemID pgtype.UUID) (string, error) {
	row := q.db.QueryRow(ctx, getItemEmbedding, itemID)
	var embedding string
	err := row.Scan(&embedding)
	return embedding, err
}

const getItemRatingsByItem = `-- name: GetItemRatingsByItem :many
SELECT user_id, rating, feedback, source, created_at
FROM item_ratings
WHERE item_id = $1
ORDER BY created_at DESC
LIMIT $2
`

type GetItemRatingsByItemParams struct {
	ItemID pgtype.UUID `json:"item_id"`
	Limit  int32       `json:"limit"`
}

type GetItemRatingsByItemRow struct {
	UserID    int64              `json:"user_id"`
	Rating    string             `json:"rating"`
	Feedback  pgtype.Text        `json:"feedback"`
	Source    string             `json:"source"`
	CreatedAt pgtype.Timestamptz `json:"created_at"`
}

func (q *Queries) GetItemRatingsByItem(ctx context.Context, arg GetItemRatingsByItemParams) ([]GetItemRatingsByItemRow, error) {
	rows, err := q.db.Query(ctx, getItemRatingsByItem, arg.ItemID, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetItemRatingsByItemRow
	for rows.Next() {
		var i GetItemRatingsByItemRow
		if err := rows.Scan(
			&i.UserID,
			&i.Rating,
			&i.Feedback,
			&i.Source,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getItemRatingsSince = `-- name: GetItemRatingsSince :many
SELECT rm.channel_id, ir.rating, ir.created_at
FROM item_ratings ir
JOIN items i ON ir.item_id = i.id
JOIN raw_messages rm ON i.raw_message_id = rm.id
WHERE ir.created_at >= $1
`

type GetItemRatingsSinceRow struct {
	ChannelID pgtype.UUID        `json:"channel_id"`
	Rating    string             `json:"rating"`
	CreatedAt pgtype.Timestamptz `json:"created_at"`
}

func (q *Queries) GetItemRatingsSince(ctx context.Context, createdAt pgtype.Timestamptz) ([]GetItemRatingsSinceRow, error) {
	rows, err := q.db.Query(ctx, getItemRatingsSince, createdAt)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetItemRatingsSinceRow
	for rows.Next() {
		var i GetItemRatingsSinceRow
		if err := rows.Scan(&i.ChannelID, &i.Rating, &i.CreatedAt); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getItemsForWindow = `-- name: GetItemsForWindow :many
SELECT i.id, i.raw_message_id, i.relevance_score, i.importance_score, i.topic, i.summary, i.language, i.status, i.first_seen_at, rm.tg_date, c.username as source_channel, c.title as source_channel_title, c.tg_peer_id as source_channel_id, rm.tg_message_id as source_msg_id, e.embedding
FROM items i
JOIN raw_messages rm ON i.raw_message_id = rm.id
JOIN channels c ON rm.channel_id = c.id
LEFT JOIN embeddings e ON i.id = e.item_id
WHERE rm.tg_date >= $1 AND rm.tg_date < $2
  AND i.status = 'ready'
  AND i.importance_score >= COALESCE(c.importance_threshold, $3)
  AND i.digested_at IS NULL
ORDER BY i.importance_score DESC, i.relevance_score DESC
LIMIT $4
`

type GetItemsForWindowParams struct {
	TgDate          pgtype.Timestamptz `json:"tg_date"`
	TgDate_2        pgtype.Timestamptz `json:"tg_date_2"`
	ImportanceScore float32            `json:"importance_score"`
	Limit           int32              `json:"limit"`
}

type GetItemsForWindowRow struct {
	ID                 pgtype.UUID        `json:"id"`
	RawMessageID       pgtype.UUID        `json:"raw_message_id"`
	RelevanceScore     float32            `json:"relevance_score"`
	ImportanceScore    float32            `json:"importance_score"`
	Topic              pgtype.Text        `json:"topic"`
	Summary            pgtype.Text        `json:"summary"`
	Language           pgtype.Text        `json:"language"`
	Status             string             `json:"status"`
	FirstSeenAt        pgtype.Timestamptz `json:"first_seen_at"`
	TgDate             pgtype.Timestamptz `json:"tg_date"`
	SourceChannel      pgtype.Text        `json:"source_channel"`
	SourceChannelTitle pgtype.Text        `json:"source_channel_title"`
	SourceChannelID    int64              `json:"source_channel_id"`
	SourceMsgID        int64              `json:"source_msg_id"`
	Embedding          pgvector.Vector    `json:"embedding"`
}

func (q *Queries) GetItemsForWindow(ctx context.Context, arg GetItemsForWindowParams) ([]GetItemsForWindowRow, error) {
	rows, err := q.db.Query(ctx, getItemsForWindow,
		arg.TgDate,
		arg.TgDate_2,
		arg.ImportanceScore,
		arg.Limit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetItemsForWindowRow
	for rows.Next() {
		var i GetItemsForWindowRow
		if err := rows.Scan(
			&i.ID,
			&i.RawMessageID,
			&i.RelevanceScore,
			&i.ImportanceScore,
			&i.Topic,
			&i.Summary,
			&i.Language,
			&i.Status,
			&i.FirstSeenAt,
			&i.TgDate,
			&i.SourceChannel,
			&i.SourceChannelTitle,
			&i.SourceChannelID,
			&i.SourceMsgID,
			&i.Embedding,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getItemsForWindowWithMedia = `-- name: GetItemsForWindowWithMedia :many
SELECT i.id, i.raw_message_id, i.relevance_score, i.importance_score, i.topic, i.summary, i.language, i.status, i.first_seen_at, rm.tg_date, rm.media_data, c.username as source_channel, c.title as source_channel_title, c.tg_peer_id as source_channel_id, rm.tg_message_id as source_msg_id, e.embedding
FROM items i
JOIN raw_messages rm ON i.raw_message_id = rm.id
JOIN channels c ON rm.channel_id = c.id
LEFT JOIN embeddings e ON i.id = e.item_id
WHERE rm.tg_date >= $1 AND rm.tg_date < $2
  AND i.status = 'ready'
  AND i.importance_score >= COALESCE(c.importance_threshold, $3)
  AND i.digested_at IS NULL
ORDER BY i.importance_score DESC, i.relevance_score DESC
LIMIT $4
`

type GetItemsForWindowWithMediaParams struct {
	TgDate          pgtype.Timestamptz `json:"tg_date"`
	TgDate_2        pgtype.Timestamptz `json:"tg_date_2"`
	ImportanceScore float32            `json:"importance_score"`
	Limit           int32              `json:"limit"`
}

type GetItemsForWindowWithMediaRow struct {
	ID                 pgtype.UUID        `json:"id"`
	RawMessageID       pgtype.UUID        `json:"raw_message_id"`
	RelevanceScore     float32            `json:"relevance_score"`
	ImportanceScore    float32            `json:"importance_score"`
	Topic              pgtype.Text        `json:"topic"`
	Summary            pgtype.Text        `json:"summary"`
	Language           pgtype.Text        `json:"language"`
	Status             string             `json:"status"`
	FirstSeenAt        pgtype.Timestamptz `json:"first_seen_at"`
	TgDate             pgtype.Timestamptz `json:"tg_date"`
	MediaData          []byte             `json:"media_data"`
	SourceChannel      pgtype.Text        `json:"source_channel"`
	SourceChannelTitle pgtype.Text        `json:"source_channel_title"`
	SourceChannelID    int64              `json:"source_channel_id"`
	SourceMsgID        int64              `json:"source_msg_id"`
	Embedding          pgvector.Vector    `json:"embedding"`
}

func (q *Queries) GetItemsForWindowWithMedia(ctx context.Context, arg GetItemsForWindowWithMediaParams) ([]GetItemsForWindowWithMediaRow, error) {
	rows, err := q.db.Query(ctx, getItemsForWindowWithMedia,
		arg.TgDate,
		arg.TgDate_2,
		arg.ImportanceScore,
		arg.Limit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetItemsForWindowWithMediaRow
	for rows.Next() {
		var i GetItemsForWindowWithMediaRow
		if err := rows.Scan(
			&i.ID,
			&i.RawMessageID,
			&i.RelevanceScore,
			&i.ImportanceScore,
			&i.Topic,
			&i.Summary,
			&i.Language,
			&i.Status,
			&i.FirstSeenAt,
			&i.TgDate,
			&i.MediaData,
			&i.SourceChannel,
			&i.SourceChannelTitle,
			&i.SourceChannelID,
			&i.SourceMsgID,
			&i.Embedding,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getLastPostedDigest = `-- name: GetLastPostedDigest :one
SELECT window_start, window_end, posted_at FROM digests WHERE status = 'posted' ORDER BY posted_at DESC LIMIT 1
`

type GetLastPostedDigestRow struct {
	WindowStart pgtype.Timestamptz `json:"window_start"`
	WindowEnd   pgtype.Timestamptz `json:"window_end"`
	PostedAt    pgtype.Timestamptz `json:"posted_at"`
}

func (q *Queries) GetLastPostedDigest(ctx context.Context) (GetLastPostedDigestRow, error) {
	row := q.db.QueryRow(ctx, getLastPostedDigest)
	var i GetLastPostedDigestRow
	err := row.Scan(&i.WindowStart, &i.WindowEnd, &i.PostedAt)
	return i, err
}

const getLatestChannelRatingStats = `-- name: GetLatestChannelRatingStats :many
WITH latest AS (
    SELECT MAX(period_end) AS period_end FROM channel_rating_stats
)
SELECT crs.channel_id,
       c.username,
       c.title,
       crs.period_start,
       crs.period_end,
       crs.weighted_good,
       crs.weighted_bad,
       crs.weighted_irrelevant,
       crs.weighted_total,
       crs.rating_count
FROM channel_rating_stats crs
JOIN latest l ON crs.period_end = l.period_end
JOIN channels c ON c.id = crs.channel_id
ORDER BY crs.weighted_total DESC
LIMIT $1
`

type GetLatestChannelRatingStatsRow struct {
	ChannelID          pgtype.UUID `json:"channel_id"`
	Username           pgtype.Text `json:"username"`
	Title              pgtype.Text `json:"title"`
	PeriodStart        pgtype.Date `json:"period_start"`
	PeriodEnd          pgtype.Date `json:"period_end"`
	WeightedGood       float64     `json:"weighted_good"`
	WeightedBad        float64     `json:"weighted_bad"`
	WeightedIrrelevant float64     `json:"weighted_irrelevant"`
	WeightedTotal      float64     `json:"weighted_total"`
	RatingCount        int32       `json:"rating_count"`
}

func (q *Queries) GetLatestChannelRatingStats(ctx context.Context, limit int32) ([]GetLatestChannelRatingStatsRow, error) {
	rows, err := q.db.Query(ctx, getLatestChannelRatingStats, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetLatestChannelRatingStatsRow
	for rows.Next() {
		var i GetLatestChannelRatingStatsRow
		if err := rows.Scan(
			&i.ChannelID,
			&i.Username,
			&i.Title,
			&i.PeriodStart,
			&i.PeriodEnd,
			&i.WeightedGood,
			&i.WeightedBad,
			&i.WeightedIrrelevant,
			&i.WeightedTotal,
			&i.RatingCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getLatestGlobalRatingStats = `-- name: GetLatestGlobalRatingStats :one
SELECT period_start,
       period_end,
       weighted_good,
       weighted_bad,
       weighted_irrelevant,
       weighted_total,
       rating_count
FROM global_rating_stats
ORDER BY period_end DESC
LIMIT 1
`

type GetLatestGlobalRatingStatsRow struct {
	PeriodStart        pgtype.Date `json:"period_start"`
	PeriodEnd          pgtype.Date `json:"period_end"`
	WeightedGood       float64     `json:"weighted_good"`
	WeightedBad        float64     `json:"weighted_bad"`
	WeightedIrrelevant float64     `json:"weighted_irrelevant"`
	WeightedTotal      float64     `json:"weighted_total"`
	RatingCount        int32       `json:"rating_count"`
}

func (q *Queries) GetLatestGlobalRatingStats(ctx context.Context) (GetLatestGlobalRatingStatsRow, error) {
	row := q.db.QueryRow(ctx, getLatestGlobalRatingStats)
	var i GetLatestGlobalRatingStatsRow
	err := row.Scan(
		&i.PeriodStart,
		&i.PeriodEnd,
		&i.WeightedGood,
		&i.WeightedBad,
		&i.WeightedIrrelevant,
		&i.WeightedTotal,
		&i.RatingCount,
	)
	return i, err
}

const getLinkCache = `-- name: GetLinkCache :one
SELECT id, url, domain, link_type, title, content, author, published_at, description, image_url, word_count, channel_username, channel_title, channel_id, message_id, views, forwards, has_media, media_type, status, error_message, language, resolved_at, created_at, expires_at, canonical_url, canonical_domain FROM link_cache WHERE url = $1
`

func (q *Queries) GetLinkCache(ctx context.Context, url string) (LinkCache, error) {
	row := q.db.QueryRow(ctx, getLinkCache, url)
	var i LinkCache
	err := row.Scan(
		&i.ID,
		&i.Url,
		&i.Domain,
		&i.LinkType,
		&i.Title,
		&i.Content,
		&i.Author,
		&i.PublishedAt,
		&i.Description,
		&i.ImageUrl,
		&i.WordCount,
		&i.ChannelUsername,
		&i.ChannelTitle,
		&i.ChannelID,
		&i.MessageID,
		&i.Views,
		&i.Forwards,
		&i.HasMedia,
		&i.MediaType,
		&i.Status,
		&i.ErrorMessage,
		&i.Language,
		&i.ResolvedAt,
		&i.CreatedAt,
		&i.ExpiresAt,
		&i.CanonicalUrl,
		&i.CanonicalDomain,
	)
	return i, err
}

const getLinksForMessage = `-- name: GetLinksForMessage :many
SELECT lc.id, lc.url, lc.domain, lc.link_type, lc.title, lc.content, lc.author, lc.published_at, lc.description, lc.image_url, lc.word_count, lc.channel_username, lc.channel_title, lc.channel_id, lc.message_id, lc.views, lc.forwards, lc.has_media, lc.media_type, lc.status, lc.error_message, lc.language, lc.resolved_at, lc.created_at, lc.expires_at, lc.canonical_url, lc.canonical_domain
FROM link_cache lc
JOIN message_links ml ON lc.id = ml.link_cache_id
WHERE ml.raw_message_id = $1
ORDER BY ml.position
`

func (q *Queries) GetLinksForMessage(ctx context.Context, rawMessageID pgtype.UUID) ([]LinkCache, error) {
	rows, err := q.db.Query(ctx, getLinksForMessage, rawMessageID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []LinkCache
	for rows.Next() {
		var i LinkCache
		if err := rows.Scan(
			&i.ID,
			&i.Url,
			&i.Domain,
			&i.LinkType,
			&i.Title,
			&i.Content,
			&i.Author,
			&i.PublishedAt,
			&i.Description,
			&i.ImageUrl,
			&i.WordCount,
			&i.ChannelUsername,
			&i.ChannelTitle,
			&i.ChannelID,
			&i.MessageID,
			&i.Views,
			&i.Forwards,
			&i.HasMedia,
			&i.MediaType,
			&i.Status,
			&i.ErrorMessage,
			&i.Language,
			&i.ResolvedAt,
			&i.CreatedAt,
			&i.ExpiresAt,
			&i.CanonicalUrl,
			&i.CanonicalDomain,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPendingBulletsForDedup = `-- name: GetPendingBulletsForDedup :many
SELECT id, text, embedding, item_id, importance_score, status
FROM item_bullets
WHERE embedding IS NOT NULL
  AND (
    status = 'pending'
    OR (status = 'ready' AND created_at >= NOW() - $1::interval)
  )
ORDER BY
  CASE WHEN status = 'ready' THEN 0 ELSE 1 END,  -- Ready bullets first (candidates)
  importance_score DESC
`

type GetPendingBulletsForDedupRow struct {
	ID              pgtype.UUID     `json:"id"`
	Text            string          `json:"text"`
	Embedding       pgvector.Vector `json:"embedding"`
	ItemID          pgtype.UUID     `json:"item_id"`
	ImportanceScore pgtype.Float4   `json:"importance_score"`
	Status          pgtype.Text     `json:"status"`
}

// Returns pending bullets plus recent ready bullets for global deduplication.
// Ready bullets within the lookback window serve as canonical candidates.
// Pending bullets are ordered last so they get deduplicated against ready bullets.
func (q *Queries) GetPendingBulletsForDedup(ctx context.Context, dollar_1 pgtype.Interval) ([]GetPendingBulletsForDedupRow, error) {
	rows, err := q.db.Query(ctx, getPendingBulletsForDedup, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPendingBulletsForDedupRow
	for rows.Next() {
		var i GetPendingBulletsForDedupRow
		if err := rows.Scan(
			&i.ID,
			&i.Text,
			&i.Embedding,
			&i.ItemID,
			&i.ImportanceScore,
			&i.Status,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPendingDiscoveries = `-- name: GetPendingDiscoveries :many
SELECT id, username, tg_peer_id, invite_link, title, description, source_type, discovery_count, first_seen_at, last_seen_at, max_views, max_forwards, engagement_score FROM (
  SELECT DISTINCT ON (dc.username)
    dc.id, dc.username, dc.tg_peer_id, dc.invite_link, dc.title, dc.description, dc.source_type,
    dc.discovery_count, dc.first_seen_at, dc.last_seen_at, dc.max_views, dc.max_forwards, dc.engagement_score
  FROM discovered_channels dc
  WHERE dc.status = 'pending'
    AND dc.username IS NOT NULL AND dc.username != ''
    AND dc.matched_channel_id IS NULL
    AND dc.discovery_count >= $1
    AND dc.engagement_score >= $2
    AND NOT EXISTS (
      SELECT 1
      FROM channels c
      WHERE c.is_active = TRUE AND (
        (c.username != '' AND lower(c.username) = lower(dc.username)) OR
        (c.username != '' AND lower('@' || c.username) = lower(dc.username)) OR
        (c.tg_peer_id = dc.tg_peer_id AND dc.tg_peer_id != 0 AND c.tg_peer_id != 0) OR
        (c.invite_link = dc.invite_link AND dc.invite_link != '' AND c.invite_link != '')
      )
    )
  ORDER BY dc.username, dc.engagement_score DESC
) deduped
ORDER BY engagement_score DESC, discovery_count DESC, last_seen_at DESC
LIMIT $3
`

type GetPendingDiscoveriesParams struct {
	DiscoveryCount  int32         `json:"discovery_count"`
	EngagementScore pgtype.Float4 `json:"engagement_score"`
	Limit           int32         `json:"limit"`
}

type GetPendingDiscoveriesRow struct {
	ID              pgtype.UUID        `json:"id"`
	Username        pgtype.Text        `json:"username"`
	TgPeerID        pgtype.Int8        `json:"tg_peer_id"`
	InviteLink      pgtype.Text        `json:"invite_link"`
	Title           pgtype.Text        `json:"title"`
	Description     pgtype.Text        `json:"description"`
	SourceType      string             `json:"source_type"`
	DiscoveryCount  int32              `json:"discovery_count"`
	FirstSeenAt     pgtype.Timestamptz `json:"first_seen_at"`
	LastSeenAt      pgtype.Timestamptz `json:"last_seen_at"`
	MaxViews        pgtype.Int4        `json:"max_views"`
	MaxForwards     pgtype.Int4        `json:"max_forwards"`
	EngagementScore pgtype.Float4      `json:"engagement_score"`
}

// Only return actionable discoveries (with username for approve/reject)
// Uses DISTINCT ON to deduplicate multiple rows for the same channel (discovered via different identifiers)
func (q *Queries) GetPendingDiscoveries(ctx context.Context, arg GetPendingDiscoveriesParams) ([]GetPendingDiscoveriesRow, error) {
	rows, err := q.db.Query(ctx, getPendingDiscoveries, arg.DiscoveryCount, arg.EngagementScore, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPendingDiscoveriesRow
	for rows.Next() {
		var i GetPendingDiscoveriesRow
		if err := rows.Scan(
			&i.ID,
			&i.Username,
			&i.TgPeerID,
			&i.InviteLink,
			&i.Title,
			&i.Description,
			&i.SourceType,
			&i.DiscoveryCount,
			&i.FirstSeenAt,
			&i.LastSeenAt,
			&i.MaxViews,
			&i.MaxForwards,
			&i.EngagementScore,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPendingDiscoveriesForFiltering = `-- name: GetPendingDiscoveriesForFiltering :many
SELECT id, username, tg_peer_id, invite_link, title, description, source_type, discovery_count, first_seen_at, last_seen_at, max_views, max_forwards, engagement_score FROM (
  SELECT DISTINCT ON (dc.username)
    dc.id, dc.username, dc.tg_peer_id, dc.invite_link, dc.title, dc.description, dc.source_type,
    dc.discovery_count, dc.first_seen_at, dc.last_seen_at, dc.max_views, dc.max_forwards, dc.engagement_score
  FROM discovered_channels dc
  WHERE dc.status = 'pending'
    AND dc.username IS NOT NULL AND dc.username != ''
    AND dc.matched_channel_id IS NULL
    AND dc.discovery_count >= $1
    AND dc.engagement_score >= $2
    AND NOT EXISTS (
      SELECT 1
      FROM channels c
      WHERE c.is_active = TRUE AND (
        (c.username != '' AND lower(c.username) = lower(dc.username)) OR
        (c.username != '' AND lower('@' || c.username) = lower(dc.username)) OR
        (c.tg_peer_id = dc.tg_peer_id AND dc.tg_peer_id != 0 AND c.tg_peer_id != 0) OR
        (c.invite_link = dc.invite_link AND dc.invite_link != '' AND c.invite_link != '')
      )
    )
  ORDER BY dc.username, dc.engagement_score DESC
) deduped
ORDER BY engagement_score DESC, discovery_count DESC, last_seen_at DESC
`

type GetPendingDiscoveriesForFilteringParams struct {
	DiscoveryCount  int32         `json:"discovery_count"`
	EngagementScore pgtype.Float4 `json:"engagement_score"`
}

type GetPendingDiscoveriesForFilteringRow struct {
	ID              pgtype.UUID        `json:"id"`
	Username        pgtype.Text        `json:"username"`
	TgPeerID        pgtype.Int8        `json:"tg_peer_id"`
	InviteLink      pgtype.Text        `json:"invite_link"`
	Title           pgtype.Text        `json:"title"`
	Description     pgtype.Text        `json:"description"`
	SourceType      string             `json:"source_type"`
	DiscoveryCount  int32              `json:"discovery_count"`
	FirstSeenAt     pgtype.Timestamptz `json:"first_seen_at"`
	LastSeenAt      pgtype.Timestamptz `json:"last_seen_at"`
	MaxViews        pgtype.Int4        `json:"max_views"`
	MaxForwards     pgtype.Int4        `json:"max_forwards"`
	EngagementScore pgtype.Float4      `json:"engagement_score"`
}

// Same as GetPendingDiscoveries but without a limit, used for keyword filtering stats.
func (q *Queries) GetPendingDiscoveriesForFiltering(ctx context.Context, arg GetPendingDiscoveriesForFilteringParams) ([]GetPendingDiscoveriesForFilteringRow, error) {
	rows, err := q.db.Query(ctx, getPendingDiscoveriesForFiltering, arg.DiscoveryCount, arg.EngagementScore)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPendingDiscoveriesForFilteringRow
	for rows.Next() {
		var i GetPendingDiscoveriesForFilteringRow
		if err := rows.Scan(
			&i.ID,
			&i.Username,
			&i.TgPeerID,
			&i.InviteLink,
			&i.Title,
			&i.Description,
			&i.SourceType,
			&i.DiscoveryCount,
			&i.FirstSeenAt,
			&i.LastSeenAt,
			&i.MaxViews,
			&i.MaxForwards,
			&i.EngagementScore,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getRecentErrors = `-- name: GetRecentErrors :many
SELECT i.id, i.raw_message_id, i.error_json, i.created_at, c.username as channel_username, c.tg_peer_id as channel_peer_id, rm.tg_message_id as source_msg_id
FROM items i
JOIN raw_messages rm ON i.raw_message_id = rm.id
JOIN channels c ON rm.channel_id = c.id
WHERE i.status = 'error'
ORDER BY i.created_at DESC
LIMIT $1
`

type GetRecentErrorsRow struct {
	ID              pgtype.UUID        `json:"id"`
	RawMessageID    pgtype.UUID        `json:"raw_message_id"`
	ErrorJson       []byte             `json:"error_json"`
	CreatedAt       pgtype.Timestamptz `json:"created_at"`
	ChannelUsername pgtype.Text        `json:"channel_username"`
	ChannelPeerID   int64              `json:"channel_peer_id"`
	SourceMsgID     int64              `json:"source_msg_id"`
}

func (q *Queries) GetRecentErrors(ctx context.Context, limit int32) ([]GetRecentErrorsRow, error) {
	rows, err := q.db.Query(ctx, getRecentErrors, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetRecentErrorsRow
	for rows.Next() {
		var i GetRecentErrorsRow
		if err := rows.Scan(
			&i.ID,
			&i.RawMessageID,
			&i.ErrorJson,
			&i.CreatedAt,
			&i.ChannelUsername,
			&i.ChannelPeerID,
			&i.SourceMsgID,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getRecentMessagesForChannel = `-- name: GetRecentMessagesForChannel :many
SELECT text, tg_date FROM raw_messages
WHERE channel_id = $1 AND processed_at IS NOT NULL AND tg_date < $2
ORDER BY tg_date DESC
LIMIT $3
`

type GetRecentMessagesForChannelParams struct {
	ChannelID pgtype.UUID        `json:"channel_id"`
	TgDate    pgtype.Timestamptz `json:"tg_date"`
	Limit     int32              `json:"limit"`
}

type GetRecentMessagesForChannelRow struct {
	Text   pgtype.Text        `json:"text"`
	TgDate pgtype.Timestamptz `json:"tg_date"`
}

func (q *Queries) GetRecentMessagesForChannel(ctx context.Context, arg GetRecentMessagesForChannelParams) ([]GetRecentMessagesForChannelRow, error) {
	rows, err := q.db.Query(ctx, getRecentMessagesForChannel, arg.ChannelID, arg.TgDate, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetRecentMessagesForChannelRow
	for rows.Next() {
		var i GetRecentMessagesForChannelRow
		if err := rows.Scan(&i.Text, &i.TgDate); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getRecentSettingHistory = `-- name: GetRecentSettingHistory :many
SELECT key, old_value, new_value, changed_by, changed_at
FROM setting_history
ORDER BY changed_at DESC
LIMIT $1
`

type GetRecentSettingHistoryRow struct {
	Key       string             `json:"key"`
	OldValue  pgtype.Text        `json:"old_value"`
	NewValue  pgtype.Text        `json:"new_value"`
	ChangedBy int64              `json:"changed_by"`
	ChangedAt pgtype.Timestamptz `json:"changed_at"`
}

func (q *Queries) GetRecentSettingHistory(ctx context.Context, limit int32) ([]GetRecentSettingHistoryRow, error) {
	rows, err := q.db.Query(ctx, getRecentSettingHistory, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetRecentSettingHistoryRow
	for rows.Next() {
		var i GetRecentSettingHistoryRow
		if err := rows.Scan(
			&i.Key,
			&i.OldValue,
			&i.NewValue,
			&i.ChangedBy,
			&i.ChangedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getRejectedDiscoveries = `-- name: GetRejectedDiscoveries :many
SELECT dc.id, dc.username, dc.tg_peer_id, dc.invite_link, dc.title, dc.description, dc.source_type,
       dc.discovery_count, dc.first_seen_at, dc.last_seen_at, dc.max_views, dc.max_forwards, dc.engagement_score
FROM discovered_channels dc
WHERE dc.status = 'rejected'
ORDER BY dc.last_seen_at DESC
LIMIT $1
`

type GetRejectedDiscoveriesRow struct {
	ID              pgtype.UUID        `json:"id"`
	Username        pgtype.Text        `json:"username"`
	TgPeerID        pgtype.Int8        `json:"tg_peer_id"`
	InviteLink      pgtype.Text        `json:"invite_link"`
	Title           pgtype.Text        `json:"title"`
	Description     pgtype.Text        `json:"description"`
	SourceType      string             `json:"source_type"`
	DiscoveryCount  int32              `json:"discovery_count"`
	FirstSeenAt     pgtype.Timestamptz `json:"first_seen_at"`
	LastSeenAt      pgtype.Timestamptz `json:"last_seen_at"`
	MaxViews        pgtype.Int4        `json:"max_views"`
	MaxForwards     pgtype.Int4        `json:"max_forwards"`
	EngagementScore pgtype.Float4      `json:"engagement_score"`
}

func (q *Queries) GetRejectedDiscoveries(ctx context.Context, limit int32) ([]GetRejectedDiscoveriesRow, error) {
	rows, err := q.db.Query(ctx, getRejectedDiscoveries, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetRejectedDiscoveriesRow
	for rows.Next() {
		var i GetRejectedDiscoveriesRow
		if err := rows.Scan(
			&i.ID,
			&i.Username,
			&i.TgPeerID,
			&i.InviteLink,
			&i.Title,
			&i.Description,
			&i.SourceType,
			&i.DiscoveryCount,
			&i.FirstSeenAt,
			&i.LastSeenAt,
			&i.MaxViews,
			&i.MaxForwards,
			&i.EngagementScore,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSetting = `-- name: GetSetting :one
SELECT value FROM settings WHERE key = $1
`

func (q *Queries) GetSetting(ctx context.Context, key string) ([]byte, error) {
	row := q.db.QueryRow(ctx, getSetting, key)
	var value []byte
	err := row.Scan(&value)
	return value, err
}

const getSummaryCache = `-- name: GetSummaryCache :one

SELECT canonical_hash,
       digest_language,
       summary,
       topic,
       language,
       relevance_score,
       importance_score,
       updated_at
FROM summary_cache
WHERE canonical_hash = $1 AND digest_language = $2
`

type GetSummaryCacheParams struct {
	CanonicalHash  string `json:"canonical_hash"`
	DigestLanguage string `json:"digest_language"`
}

type GetSummaryCacheRow struct {
	CanonicalHash   string             `json:"canonical_hash"`
	DigestLanguage  string             `json:"digest_language"`
	Summary         string             `json:"summary"`
	Topic           pgtype.Text        `json:"topic"`
	Language        pgtype.Text        `json:"language"`
	RelevanceScore  float32            `json:"relevance_score"`
	ImportanceScore float32            `json:"importance_score"`
	UpdatedAt       pgtype.Timestamptz `json:"updated_at"`
}

// Summary Cache queries
func (q *Queries) GetSummaryCache(ctx context.Context, arg GetSummaryCacheParams) (GetSummaryCacheRow, error) {
	row := q.db.QueryRow(ctx, getSummaryCache, arg.CanonicalHash, arg.DigestLanguage)
	var i GetSummaryCacheRow
	err := row.Scan(
		&i.CanonicalHash,
		&i.DigestLanguage,
		&i.Summary,
		&i.Topic,
		&i.Language,
		&i.RelevanceScore,
		&i.ImportanceScore,
		&i.UpdatedAt,
	)
	return i, err
}

const getUnprocessedMessages = `-- name: GetUnprocessedMessages :many
WITH eligible AS (
    SELECT rm.id
    FROM raw_messages rm
    LEFT JOIN items i ON rm.id = i.raw_message_id
    WHERE (rm.processed_at IS NULL AND rm.processing_started_at IS NULL)
       OR (i.status IN ('error', 'retry') AND i.retry_count < 5 AND (i.next_retry_at IS NULL OR i.next_retry_at < now()))
    ORDER BY rm.tg_date ASC
    LIMIT $1
    FOR UPDATE OF rm SKIP LOCKED
),
claimed AS (
    UPDATE raw_messages rm
    SET processing_started_at = now()
    FROM eligible
    WHERE rm.id = eligible.id
    RETURNING rm.id
)
SELECT rm.id, rm.channel_id, rm.tg_message_id, rm.tg_date, rm.text, rm.preview_text, rm.entities_json, rm.media_json, rm.media_data, rm.canonical_hash, rm.is_forward,
       c.title as channel_title, c.context as channel_context, c.description as channel_description,
       c.category as channel_category, c.tone as channel_tone, c.update_freq as channel_update_freq,
       c.relevance_threshold as channel_relevance_threshold, c.importance_threshold as channel_importance_threshold,
       c.importance_weight as channel_importance_weight,
       c.auto_relevance_enabled as channel_auto_relevance_enabled,
       c.relevance_threshold_delta as channel_relevance_threshold_delta,
       c.tg_peer_id as channel_tg_peer_id
FROM raw_messages rm
JOIN channels c ON rm.channel_id = c.id
WHERE rm.id IN (SELECT id FROM claimed)
ORDER BY rm.tg_date ASC
`

type GetUnprocessedMessagesRow struct {
	ID                             pgtype.UUID        `json:"id"`
	ChannelID                      pgtype.UUID        `json:"channel_id"`
	TgMessageID                    int64              `json:"tg_message_id"`
	TgDate                         pgtype.Timestamptz `json:"tg_date"`
	Text                           pgtype.Text        `json:"text"`
	PreviewText                    pgtype.Text        `json:"preview_text"`
	EntitiesJson                   []byte             `json:"entities_json"`
	MediaJson                      []byte             `json:"media_json"`
	MediaData                      []byte             `json:"media_data"`
	CanonicalHash                  string             `json:"canonical_hash"`
	IsForward                      bool               `json:"is_forward"`
	ChannelTitle                   pgtype.Text        `json:"channel_title"`
	ChannelContext                 pgtype.Text        `json:"channel_context"`
	ChannelDescription             pgtype.Text        `json:"channel_description"`
	ChannelCategory                pgtype.Text        `json:"channel_category"`
	ChannelTone                    pgtype.Text        `json:"channel_tone"`
	ChannelUpdateFreq              pgtype.Text        `json:"channel_update_freq"`
	ChannelRelevanceThreshold      pgtype.Float4      `json:"channel_relevance_threshold"`
	ChannelImportanceThreshold     pgtype.Float4      `json:"channel_importance_threshold"`
	ChannelImportanceWeight        pgtype.Float4      `json:"channel_importance_weight"`
	ChannelAutoRelevanceEnabled    pgtype.Bool        `json:"channel_auto_relevance_enabled"`
	ChannelRelevanceThresholdDelta pgtype.Float4      `json:"channel_relevance_threshold_delta"`
	ChannelTgPeerID                int64              `json:"channel_tg_peer_id"`
}

// Uses FOR UPDATE SKIP LOCKED to prevent multiple workers from claiming the same messages.
// Atomically claims messages by setting processing_started_at.
func (q *Queries) GetUnprocessedMessages(ctx context.Context, limit int32) ([]GetUnprocessedMessagesRow, error) {
	rows, err := q.db.Query(ctx, getUnprocessedMessages, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetUnprocessedMessagesRow
	for rows.Next() {
		var i GetUnprocessedMessagesRow
		if err := rows.Scan(
			&i.ID,
			&i.ChannelID,
			&i.TgMessageID,
			&i.TgDate,
			&i.Text,
			&i.PreviewText,
			&i.EntitiesJson,
			&i.MediaJson,
			&i.MediaData,
			&i.CanonicalHash,
			&i.IsForward,
			&i.ChannelTitle,
			&i.ChannelContext,
			&i.ChannelDescription,
			&i.ChannelCategory,
			&i.ChannelTone,
			&i.ChannelUpdateFreq,
			&i.ChannelRelevanceThreshold,
			&i.ChannelImportanceThreshold,
			&i.ChannelImportanceWeight,
			&i.ChannelAutoRelevanceEnabled,
			&i.ChannelRelevanceThresholdDelta,
			&i.ChannelTgPeerID,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const incrementDiscoveryResolutionAttempts = `-- name: IncrementDiscoveryResolutionAttempts :exec
UPDATE discovered_channels
SET resolution_attempts = COALESCE(resolution_attempts, 0) + 1,
    last_resolution_attempt = now()
WHERE id = $1
`

func (q *Queries) IncrementDiscoveryResolutionAttempts(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, incrementDiscoveryResolutionAttempts, id)
	return err
}

const insertBullet = `-- name: InsertBullet :one

INSERT INTO item_bullets (item_id, bullet_index, text, topic, relevance_score, importance_score, bullet_hash, status)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
RETURNING id
`

type InsertBulletParams struct {
	ItemID          pgtype.UUID   `json:"item_id"`
	BulletIndex     int32         `json:"bullet_index"`
	Text            string        `json:"text"`
	Topic           pgtype.Text   `json:"topic"`
	RelevanceScore  pgtype.Float4 `json:"relevance_score"`
	ImportanceScore pgtype.Float4 `json:"importance_score"`
	BulletHash      pgtype.Text   `json:"bullet_hash"`
	Status          pgtype.Text   `json:"status"`
}

// ============================================================================
// Bullet extraction queries
// ============================================================================
func (q *Queries) InsertBullet(ctx context.Context, arg InsertBulletParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, insertBullet,
		arg.ItemID,
		arg.BulletIndex,
		arg.Text,
		arg.Topic,
		arg.RelevanceScore,
		arg.ImportanceScore,
		arg.BulletHash,
		arg.Status,
	)
	var id pgtype.UUID
	err := row.Scan(&id)
	return id, err
}

const insertThresholdTuningLog = `-- name: InsertThresholdTuningLog :exec
INSERT INTO threshold_tuning_log (
    tuned_at,
    net_score,
    delta,
    relevance_threshold,
    importance_threshold
)
VALUES ($1, $2, $3, $4, $5)
`

type InsertThresholdTuningLogParams struct {
	TunedAt             pgtype.Timestamptz `json:"tuned_at"`
	NetScore            float64            `json:"net_score"`
	Delta               float32            `json:"delta"`
	RelevanceThreshold  float32            `json:"relevance_threshold"`
	ImportanceThreshold float32            `json:"importance_threshold"`
}

func (q *Queries) InsertThresholdTuningLog(ctx context.Context, arg InsertThresholdTuningLogParams) error {
	_, err := q.db.Exec(ctx, insertThresholdTuningLog,
		arg.TunedAt,
		arg.NetScore,
		arg.Delta,
		arg.RelevanceThreshold,
		arg.ImportanceThreshold,
	)
	return err
}

const isChannelDiscoveredRejected = `-- name: IsChannelDiscoveredRejected :one
SELECT EXISTS(
    SELECT 1 FROM discovered_channels
    WHERE status = 'rejected' AND (
        (username != '' AND lower(username) = lower($1)) OR
        (tg_peer_id = $2 AND tg_peer_id != 0) OR
        (invite_link = $3 AND invite_link != '')
    )
)
`

type IsChannelDiscoveredRejectedParams struct {
	Lower      string      `json:"lower"`
	TgPeerID   pgtype.Int8 `json:"tg_peer_id"`
	InviteLink pgtype.Text `json:"invite_link"`
}

func (q *Queries) IsChannelDiscoveredRejected(ctx context.Context, arg IsChannelDiscoveredRejectedParams) (bool, error) {
	row := q.db.QueryRow(ctx, isChannelDiscoveredRejected, arg.Lower, arg.TgPeerID, arg.InviteLink)
	var exists bool
	err := row.Scan(&exists)
	return exists, err
}

const isChannelTracked = `-- name: IsChannelTracked :one
SELECT EXISTS(
    SELECT 1 FROM channels
    WHERE is_active = TRUE AND (
        (username != '' AND lower(username) = lower($1)) OR
        (tg_peer_id = $2 AND tg_peer_id != 0) OR
        (invite_link = $3 AND invite_link != '')
    )
)
`

type IsChannelTrackedParams struct {
	Lower      string      `json:"lower"`
	TgPeerID   int64       `json:"tg_peer_id"`
	InviteLink pgtype.Text `json:"invite_link"`
}

func (q *Queries) IsChannelTracked(ctx context.Context, arg IsChannelTrackedParams) (bool, error) {
	row := q.db.QueryRow(ctx, isChannelTracked, arg.Lower, arg.TgPeerID, arg.InviteLink)
	var exists bool
	err := row.Scan(&exists)
	return exists, err
}

const linkMessageToLink = `-- name: LinkMessageToLink :exec
INSERT INTO message_links (raw_message_id, link_cache_id, position)
VALUES ($1, $2, $3)
ON CONFLICT (raw_message_id, link_cache_id) DO NOTHING
`

type LinkMessageToLinkParams struct {
	RawMessageID pgtype.UUID `json:"raw_message_id"`
	LinkCacheID  pgtype.UUID `json:"link_cache_id"`
	Position     pgtype.Int4 `json:"position"`
}

func (q *Queries) LinkMessageToLink(ctx context.Context, arg LinkMessageToLinkParams) error {
	_, err := q.db.Exec(ctx, linkMessageToLink, arg.RawMessageID, arg.LinkCacheID, arg.Position)
	return err
}

const markAsProcessed = `-- name: MarkAsProcessed :exec
UPDATE raw_messages SET processed_at = now(), processing_started_at = NULL WHERE id = $1
`

func (q *Queries) MarkAsProcessed(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, markAsProcessed, id)
	return err
}

const markBulletAsCanonical = `-- name: MarkBulletAsCanonical :exec
UPDATE item_bullets
SET status = 'ready', bullet_cluster_id = id
WHERE id = $1
`

func (q *Queries) MarkBulletAsCanonical(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, markBulletAsCanonical, id)
	return err
}

const markBulletAsDuplicateOf = `-- name: MarkBulletAsDuplicateOf :exec
UPDATE item_bullets
SET status = 'duplicate', bullet_cluster_id = $2
WHERE id = $1
`

type MarkBulletAsDuplicateOfParams struct {
	ID              pgtype.UUID `json:"id"`
	BulletClusterID pgtype.UUID `json:"bullet_cluster_id"`
}

func (q *Queries) MarkBulletAsDuplicateOf(ctx context.Context, arg MarkBulletAsDuplicateOfParams) error {
	_, err := q.db.Exec(ctx, markBulletAsDuplicateOf, arg.ID, arg.BulletClusterID)
	return err
}

const markDuplicateBullets = `-- name: MarkDuplicateBullets :exec
UPDATE item_bullets
SET status = 'duplicate'
WHERE id = ANY($1::uuid[])
`

func (q *Queries) MarkDuplicateBullets(ctx context.Context, dollar_1 []pgtype.UUID) error {
	_, err := q.db.Exec(ctx, markDuplicateBullets, dollar_1)
	return err
}

const markItemsAsDigested = `-- name: MarkItemsAsDigested :exec
UPDATE items SET digested_at = now() WHERE id = ANY($1::uuid[])
`

func (q *Queries) MarkItemsAsDigested(ctx context.Context, dollar_1 []pgtype.UUID) error {
	_, err := q.db.Exec(ctx, markItemsAsDigested, dollar_1)
	return err
}

const recoverStuckPipelineMessages = `-- name: RecoverStuckPipelineMessages :execrows
UPDATE raw_messages
SET processing_started_at = NULL
WHERE processing_started_at IS NOT NULL
  AND processed_at IS NULL
  AND processing_started_at < now() - $1::interval
`

// Recovers messages that were claimed but not processed within the timeout.
// This handles cases where a worker crashed after claiming messages.
func (q *Queries) RecoverStuckPipelineMessages(ctx context.Context, dollar_1 pgtype.Interval) (int64, error) {
	result, err := q.db.Exec(ctx, recoverStuckPipelineMessages, dollar_1)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected(), nil
}

const releaseAdvisoryLock = `-- name: ReleaseAdvisoryLock :exec
SELECT pg_advisory_unlock($1)
`

func (q *Queries) ReleaseAdvisoryLock(ctx context.Context, pgAdvisoryUnlock int64) error {
	_, err := q.db.Exec(ctx, releaseAdvisoryLock, pgAdvisoryUnlock)
	return err
}

const releaseClaimedMessage = `-- name: ReleaseClaimedMessage :exec
UPDATE raw_messages SET processing_started_at = NULL WHERE id = $1
`

// Releases a claimed message so it can be picked up by another worker (used on error)
func (q *Queries) ReleaseClaimedMessage(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, releaseClaimedMessage, id)
	return err
}

const releaseSchedulerLock = `-- name: ReleaseSchedulerLock :exec
DELETE FROM scheduler_locks
WHERE lock_name = $1 AND holder_id = $2
`

type ReleaseSchedulerLockParams struct {
	LockName string `json:"lock_name"`
	HolderID string `json:"holder_id"`
}

// Releases the lock if held by the specified holder
func (q *Queries) ReleaseSchedulerLock(ctx context.Context, arg ReleaseSchedulerLockParams) error {
	_, err := q.db.Exec(ctx, releaseSchedulerLock, arg.LockName, arg.HolderID)
	return err
}

const retryFailedEnrichmentItems = `-- name: RetryFailedEnrichmentItems :exec
UPDATE enrichment_queue
SET status = 'pending', error_message = NULL, attempt_count = 0, next_retry_at = NULL
WHERE status = 'error'
`

func (q *Queries) RetryFailedEnrichmentItems(ctx context.Context) error {
	_, err := q.db.Exec(ctx, retryFailedEnrichmentItems)
	return err
}

const retryFailedItems = `-- name: RetryFailedItems :exec
UPDATE items SET status = 'retry', retry_count = 0, next_retry_at = now() WHERE status = 'error'
`

func (q *Queries) RetryFailedItems(ctx context.Context) error {
	_, err := q.db.Exec(ctx, retryFailedItems)
	return err
}

const retryItem = `-- name: RetryItem :exec
UPDATE items SET status = 'retry', retry_count = 0, next_retry_at = now() WHERE id = $1 AND status = 'error'
`

func (q *Queries) RetryItem(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, retryItem, id)
	return err
}

const saveDigest = `-- name: SaveDigest :one
INSERT INTO digests (id, window_start, window_end, posted_chat_id, posted_msg_id, status, posted_at)
VALUES ($1, $2, $3, $4, $5, 'posted', now())
ON CONFLICT (window_start, window_end) DO UPDATE SET
    posted_chat_id = $4, posted_msg_id = $5, status = 'posted', posted_at = now()
RETURNING id
`

type SaveDigestParams struct {
	ID           pgtype.UUID        `json:"id"`
	WindowStart  pgtype.Timestamptz `json:"window_start"`
	WindowEnd    pgtype.Timestamptz `json:"window_end"`
	PostedChatID pgtype.Int8        `json:"posted_chat_id"`
	PostedMsgID  pgtype.Int8        `json:"posted_msg_id"`
}

func (q *Queries) SaveDigest(ctx context.Context, arg SaveDigestParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, saveDigest,
		arg.ID,
		arg.WindowStart,
		arg.WindowEnd,
		arg.PostedChatID,
		arg.PostedMsgID,
	)
	var id pgtype.UUID
	err := row.Scan(&id)
	return id, err
}

const saveDigestEntry = `-- name: SaveDigestEntry :exec
INSERT INTO digest_entries (digest_id, title, body, sources_json)
VALUES ($1, $2, $3, $4)
`

type SaveDigestEntryParams struct {
	DigestID    pgtype.UUID `json:"digest_id"`
	Title       pgtype.Text `json:"title"`
	Body        string      `json:"body"`
	SourcesJson []byte      `json:"sources_json"`
}

func (q *Queries) SaveDigestEntry(ctx context.Context, arg SaveDigestEntryParams) error {
	_, err := q.db.Exec(ctx, saveDigestEntry,
		arg.DigestID,
		arg.Title,
		arg.Body,
		arg.SourcesJson,
	)
	return err
}

const saveDigestError = `-- name: SaveDigestError :exec
INSERT INTO digests (window_start, window_end, posted_chat_id, status, error_json, posted_at)
VALUES ($1, $2, $3, 'error', $4, now())
ON CONFLICT (window_start, window_end) DO UPDATE SET
    posted_chat_id = $3, status = 'error', error_json = $4, posted_at = now()
    WHERE digests.status != 'posted'
`

type SaveDigestErrorParams struct {
	WindowStart  pgtype.Timestamptz `json:"window_start"`
	WindowEnd    pgtype.Timestamptz `json:"window_end"`
	PostedChatID pgtype.Int8        `json:"posted_chat_id"`
	ErrorJson    []byte             `json:"error_json"`
}

func (q *Queries) SaveDigestError(ctx context.Context, arg SaveDigestErrorParams) error {
	_, err := q.db.Exec(ctx, saveDigestError,
		arg.WindowStart,
		arg.WindowEnd,
		arg.PostedChatID,
		arg.ErrorJson,
	)
	return err
}

const saveEmbedding = `-- name: SaveEmbedding :exec
INSERT INTO embeddings (item_id, embedding)
VALUES ($1, $2::vector)
ON CONFLICT (item_id) DO UPDATE SET embedding = $2::vector
`

type SaveEmbeddingParams struct {
	ItemID    pgtype.UUID     `json:"item_id"`
	Embedding pgvector.Vector `json:"embedding"`
}

func (q *Queries) SaveEmbedding(ctx context.Context, arg SaveEmbeddingParams) error {
	_, err := q.db.Exec(ctx, saveEmbedding, arg.ItemID, arg.Embedding)
	return err
}

const saveItem = `-- name: SaveItem :one
INSERT INTO items (raw_message_id, relevance_score, importance_score, topic, summary, language, language_source, status, bullet_total_count, bullet_included_count, retry_count, next_retry_at, first_seen_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 0, NULL, (SELECT tg_date FROM raw_messages WHERE id = $1))
ON CONFLICT (raw_message_id) DO UPDATE SET
    relevance_score = $2, importance_score = $3, topic = $4, summary = $5, language = $6, language_source = $7, status = $8,
    bullet_total_count = $9, bullet_included_count = $10,
    retry_count = 0, next_retry_at = NULL, error_json = NULL,
    first_seen_at = COALESCE(items.first_seen_at, EXCLUDED.first_seen_at)
RETURNING id
`

type SaveItemParams struct {
	RawMessageID        pgtype.UUID `json:"raw_message_id"`
	RelevanceScore      float32     `json:"relevance_score"`
	ImportanceScore     float32     `json:"importance_score"`
	Topic               pgtype.Text `json:"topic"`
	Summary             pgtype.Text `json:"summary"`
	Language            pgtype.Text `json:"language"`
	LanguageSource      pgtype.Text `json:"language_source"`
	Status              string      `json:"status"`
	BulletTotalCount    int32       `json:"bullet_total_count"`
	BulletIncludedCount int32       `json:"bullet_included_count"`
}

func (q *Queries) SaveItem(ctx context.Context, arg SaveItemParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, saveItem,
		arg.RawMessageID,
		arg.RelevanceScore,
		arg.ImportanceScore,
		arg.Topic,
		arg.Summary,
		arg.Language,
		arg.LanguageSource,
		arg.Status,
		arg.BulletTotalCount,
		arg.BulletIncludedCount,
	)
	var id pgtype.UUID
	err := row.Scan(&id)
	return id, err
}

const saveItemError = `-- name: SaveItemError :exec
INSERT INTO items (raw_message_id, status, error_json, retry_count, next_retry_at, first_seen_at)
VALUES ($1, 'error', $2, 1, now() + interval '1 minute', (SELECT tg_date FROM raw_messages WHERE id = $1))
ON CONFLICT (raw_message_id) DO UPDATE SET 
    status = 'error', 
    error_json = $2,
    retry_count = items.retry_count + 1,
    next_retry_at = now() + (power(2, items.retry_count) * interval '1 minute'),
    first_seen_at = COALESCE(items.first_seen_at, EXCLUDED.first_seen_at)
`

type SaveItemErrorParams struct {
	RawMessageID pgtype.UUID `json:"raw_message_id"`
	ErrorJson    []byte      `json:"error_json"`
}

func (q *Queries) SaveItemError(ctx context.Context, arg SaveItemErrorParams) error {
	_, err := q.db.Exec(ctx, saveItemError, arg.RawMessageID, arg.ErrorJson)
	return err
}

const saveItemRating = `-- name: SaveItemRating :exec
INSERT INTO item_ratings (item_id, user_id, rating, feedback, source)
VALUES ($1, $2, $3, $4, $5)
ON CONFLICT (item_id, user_id) DO UPDATE SET rating = $3, feedback = $4, source = $5
`

type SaveItemRatingParams struct {
	ItemID   pgtype.UUID `json:"item_id"`
	UserID   int64       `json:"user_id"`
	Rating   string      `json:"rating"`
	Feedback pgtype.Text `json:"feedback"`
	Source   string      `json:"source"`
}

func (q *Queries) SaveItemRating(ctx context.Context, arg SaveItemRatingParams) error {
	_, err := q.db.Exec(ctx, saveItemRating,
		arg.ItemID,
		arg.UserID,
		arg.Rating,
		arg.Feedback,
		arg.Source,
	)
	return err
}

const saveLinkCache = `-- name: SaveLinkCache :one
INSERT INTO link_cache (
    url, canonical_url, canonical_domain, domain, link_type, title, content, author, published_at,
    description, image_url, word_count,
    channel_username, channel_title, channel_id, message_id,
    views, forwards, has_media, media_type,
    status, error_message, language, resolved_at, expires_at
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8,
    $9, $10, $11, $12,
    $13, $14, $15, $16,
    $17, $18, $19, $20,
    $21, $22, $23, $24, $25
)
ON CONFLICT (url) DO UPDATE SET
    canonical_url = EXCLUDED.canonical_url,
    canonical_domain = EXCLUDED.canonical_domain,
    title = EXCLUDED.title,
    content = EXCLUDED.content,
    author = EXCLUDED.author,
    published_at = EXCLUDED.published_at,
    description = EXCLUDED.description,
    image_url = EXCLUDED.image_url,
    word_count = EXCLUDED.word_count,
    channel_username = EXCLUDED.channel_username,
    channel_title = EXCLUDED.channel_title,
    channel_id = EXCLUDED.channel_id,
    message_id = EXCLUDED.message_id,
    views = EXCLUDED.views,
    forwards = EXCLUDED.forwards,
    has_media = EXCLUDED.has_media,
    media_type = EXCLUDED.media_type,
    status = EXCLUDED.status,
    error_message = EXCLUDED.error_message,
    language = EXCLUDED.language,
    resolved_at = EXCLUDED.resolved_at,
    expires_at = EXCLUDED.expires_at
RETURNING id
`

type SaveLinkCacheParams struct {
	Url             string             `json:"url"`
	CanonicalUrl    pgtype.Text        `json:"canonical_url"`
	CanonicalDomain pgtype.Text        `json:"canonical_domain"`
	Domain          string             `json:"domain"`
	LinkType        string             `json:"link_type"`
	Title           pgtype.Text        `json:"title"`
	Content         pgtype.Text        `json:"content"`
	Author          pgtype.Text        `json:"author"`
	PublishedAt     pgtype.Timestamptz `json:"published_at"`
	Description     pgtype.Text        `json:"description"`
	ImageUrl        pgtype.Text        `json:"image_url"`
	WordCount       pgtype.Int4        `json:"word_count"`
	ChannelUsername pgtype.Text        `json:"channel_username"`
	ChannelTitle    pgtype.Text        `json:"channel_title"`
	ChannelID       pgtype.Int8        `json:"channel_id"`
	MessageID       pgtype.Int8        `json:"message_id"`
	Views           pgtype.Int4        `json:"views"`
	Forwards        pgtype.Int4        `json:"forwards"`
	HasMedia        pgtype.Bool        `json:"has_media"`
	MediaType       pgtype.Text        `json:"media_type"`
	Status          string             `json:"status"`
	ErrorMessage    pgtype.Text        `json:"error_message"`
	Language        pgtype.Text        `json:"language"`
	ResolvedAt      pgtype.Timestamptz `json:"resolved_at"`
	ExpiresAt       pgtype.Timestamptz `json:"expires_at"`
}

func (q *Queries) SaveLinkCache(ctx context.Context, arg SaveLinkCacheParams) (pgtype.UUID, error) {
	row := q.db.QueryRow(ctx, saveLinkCache,
		arg.Url,
		arg.CanonicalUrl,
		arg.CanonicalDomain,
		arg.Domain,
		arg.LinkType,
		arg.Title,
		arg.Content,
		arg.Author,
		arg.PublishedAt,
		arg.Description,
		arg.ImageUrl,
		arg.WordCount,
		arg.ChannelUsername,
		arg.ChannelTitle,
		arg.ChannelID,
		arg.MessageID,
		arg.Views,
		arg.Forwards,
		arg.HasMedia,
		arg.MediaType,
		arg.Status,
		arg.ErrorMessage,
		arg.Language,
		arg.ResolvedAt,
		arg.ExpiresAt,
	)
	var id pgtype.UUID
	err := row.Scan(&id)
	return id, err
}

const saveRating = `-- name: SaveRating :exec
INSERT INTO digest_ratings (digest_id, user_id, rating, feedback)
VALUES ($1, $2, $3, $4)
ON CONFLICT (digest_id, user_id) DO UPDATE SET rating = $3, feedback = $4
`

type SaveRatingParams struct {
	DigestID pgtype.UUID `json:"digest_id"`
	UserID   int64       `json:"user_id"`
	Rating   int16       `json:"rating"`
	Feedback pgtype.Text `json:"feedback"`
}

func (q *Queries) SaveRating(ctx context.Context, arg SaveRatingParams) error {
	_, err := q.db.Exec(ctx, saveRating,
		arg.DigestID,
		arg.UserID,
		arg.Rating,
		arg.Feedback,
	)
	return err
}

const saveRawMessage = `-- name: SaveRawMessage :exec
INSERT INTO raw_messages (channel_id, tg_message_id, tg_date, text, entities_json, media_json, media_data, preview_text, canonical_hash, is_forward)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
ON CONFLICT (channel_id, tg_message_id) DO UPDATE SET
    media_data = COALESCE(raw_messages.media_data, EXCLUDED.media_data),
    preview_text = COALESCE(raw_messages.preview_text, EXCLUDED.preview_text)
WHERE raw_messages.media_data IS NULL OR raw_messages.preview_text IS NULL
`

type SaveRawMessageParams struct {
	ChannelID     pgtype.UUID        `json:"channel_id"`
	TgMessageID   int64              `json:"tg_message_id"`
	TgDate        pgtype.Timestamptz `json:"tg_date"`
	Text          pgtype.Text        `json:"text"`
	EntitiesJson  []byte             `json:"entities_json"`
	MediaJson     []byte             `json:"media_json"`
	MediaData     []byte             `json:"media_data"`
	PreviewText   pgtype.Text        `json:"preview_text"`
	CanonicalHash string             `json:"canonical_hash"`
	IsForward     bool               `json:"is_forward"`
}

func (q *Queries) SaveRawMessage(ctx context.Context, arg SaveRawMessageParams) error {
	_, err := q.db.Exec(ctx, saveRawMessage,
		arg.ChannelID,
		arg.TgMessageID,
		arg.TgDate,
		arg.Text,
		arg.EntitiesJson,
		arg.MediaJson,
		arg.MediaData,
		arg.PreviewText,
		arg.CanonicalHash,
		arg.IsForward,
	)
	return err
}

const saveRawMessageDropLog = `-- name: SaveRawMessageDropLog :exec

INSERT INTO raw_message_drop_log (raw_message_id, reason, detail)
VALUES ($1, $2, $3)
ON CONFLICT (raw_message_id) DO UPDATE SET
    reason = EXCLUDED.reason,
    detail = EXCLUDED.detail,
    updated_at = NOW()
`

type SaveRawMessageDropLogParams struct {
	RawMessageID pgtype.UUID `json:"raw_message_id"`
	Reason       string      `json:"reason"`
	Detail       pgtype.Text `json:"detail"`
}

// Drop Log queries
func (q *Queries) SaveRawMessageDropLog(ctx context.Context, arg SaveRawMessageDropLogParams) error {
	_, err := q.db.Exec(ctx, saveRawMessageDropLog, arg.RawMessageID, arg.Reason, arg.Detail)
	return err
}

const saveRelevanceGateLog = `-- name: SaveRelevanceGateLog :exec

INSERT INTO relevance_gate_log (raw_message_id, decision, confidence, reason, model, gate_version)
VALUES ($1, $2, $3, $4, $5, $6)
`

type SaveRelevanceGateLogParams struct {
	RawMessageID pgtype.UUID   `json:"raw_message_id"`
	Decision     string        `json:"decision"`
	Confidence   pgtype.Float4 `json:"confidence"`
	Reason       pgtype.Text   `json:"reason"`
	Model        pgtype.Text   `json:"model"`
	GateVersion  pgtype.Text   `json:"gate_version"`
}

// Relevance Gate Log queries
func (q *Queries) SaveRelevanceGateLog(ctx context.Context, arg SaveRelevanceGateLogParams) error {
	_, err := q.db.Exec(ctx, saveRelevanceGateLog,
		arg.RawMessageID,
		arg.Decision,
		arg.Confidence,
		arg.Reason,
		arg.Model,
		arg.GateVersion,
	)
	return err
}

const saveSetting = `-- name: SaveSetting :exec
INSERT INTO settings (key, value)
VALUES ($1, $2)
ON CONFLICT (key) DO UPDATE SET value = $2, updated_at = now()
`

type SaveSettingParams struct {
	Key   string `json:"key"`
	Value []byte `json:"value"`
}

func (q *Queries) SaveSetting(ctx context.Context, arg SaveSettingParams) error {
	_, err := q.db.Exec(ctx, saveSetting, arg.Key, arg.Value)
	return err
}

const tryAcquireAdvisoryLock = `-- name: TryAcquireAdvisoryLock :one
SELECT pg_try_advisory_lock($1)
`

func (q *Queries) TryAcquireAdvisoryLock(ctx context.Context, pgTryAdvisoryLock int64) (bool, error) {
	row := q.db.QueryRow(ctx, tryAcquireAdvisoryLock, pgTryAdvisoryLock)
	var pg_try_advisory_lock bool
	err := row.Scan(&pg_try_advisory_lock)
	return pg_try_advisory_lock, err
}

const tryAcquireSchedulerLock = `-- name: TryAcquireSchedulerLock :one
INSERT INTO scheduler_locks (lock_name, holder_id, acquired_at, expires_at)
VALUES ($1, $2, NOW(), NOW() + $3::interval)
ON CONFLICT (lock_name) DO UPDATE
SET holder_id = EXCLUDED.holder_id,
    acquired_at = NOW(),
    expires_at = NOW() + $3::interval
WHERE scheduler_locks.expires_at < NOW()
RETURNING TRUE
`

type TryAcquireSchedulerLockParams struct {
	LockName string          `json:"lock_name"`
	HolderID string          `json:"holder_id"`
	Column3  pgtype.Interval `json:"column_3"`
}

// Tries to acquire a row-based lock. Returns true if acquired.
// Automatically expires stale locks older than the specified duration.
func (q *Queries) TryAcquireSchedulerLock(ctx context.Context, arg TryAcquireSchedulerLockParams) (bool, error) {
	row := q.db.QueryRow(ctx, tryAcquireSchedulerLock, arg.LockName, arg.HolderID, arg.Column3)
	var column_1 bool
	err := row.Scan(&column_1)
	return column_1, err
}

const updateBulletEmbedding = `-- name: UpdateBulletEmbedding :exec
UPDATE item_bullets SET embedding = $2 WHERE id = $1
`

type UpdateBulletEmbeddingParams struct {
	ID        pgtype.UUID     `json:"id"`
	Embedding pgvector.Vector `json:"embedding"`
}

func (q *Queries) UpdateBulletEmbedding(ctx context.Context, arg UpdateBulletEmbeddingParams) error {
	_, err := q.db.Exec(ctx, updateBulletEmbedding, arg.ID, arg.Embedding)
	return err
}

const updateBulletStatus = `-- name: UpdateBulletStatus :exec
UPDATE item_bullets SET status = $2 WHERE id = $1
`

type UpdateBulletStatusParams struct {
	ID     pgtype.UUID `json:"id"`
	Status pgtype.Text `json:"status"`
}

func (q *Queries) UpdateBulletStatus(ctx context.Context, arg UpdateBulletStatusParams) error {
	_, err := q.db.Exec(ctx, updateBulletStatus, arg.ID, arg.Status)
	return err
}

const updateChannel = `-- name: UpdateChannel :exec
UPDATE channels SET tg_peer_id = $2, title = $3, access_hash = $4, username = $5, description = $6, category = $7, tone = $8, update_freq = $9 WHERE id = $1
`

type UpdateChannelParams struct {
	ID          pgtype.UUID `json:"id"`
	TgPeerID    int64       `json:"tg_peer_id"`
	Title       pgtype.Text `json:"title"`
	AccessHash  pgtype.Int8 `json:"access_hash"`
	Username    pgtype.Text `json:"username"`
	Description pgtype.Text `json:"description"`
	Category    pgtype.Text `json:"category"`
	Tone        pgtype.Text `json:"tone"`
	UpdateFreq  pgtype.Text `json:"update_freq"`
}

func (q *Queries) UpdateChannel(ctx context.Context, arg UpdateChannelParams) error {
	_, err := q.db.Exec(ctx, updateChannel,
		arg.ID,
		arg.TgPeerID,
		arg.Title,
		arg.AccessHash,
		arg.Username,
		arg.Description,
		arg.Category,
		arg.Tone,
		arg.UpdateFreq,
	)
	return err
}

const updateChannelAutoWeight = `-- name: UpdateChannelAutoWeight :exec
UPDATE channels
SET importance_weight = $2,
    weight_updated_at = NOW()
WHERE id = $1 AND weight_override = FALSE
`

type UpdateChannelAutoWeightParams struct {
	ID               pgtype.UUID   `json:"id"`
	ImportanceWeight pgtype.Float4 `json:"importance_weight"`
}

func (q *Queries) UpdateChannelAutoWeight(ctx context.Context, arg UpdateChannelAutoWeightParams) error {
	_, err := q.db.Exec(ctx, updateChannelAutoWeight, arg.ID, arg.ImportanceWeight)
	return err
}

const updateChannelContext = `-- name: UpdateChannelContext :exec
UPDATE channels SET context = $2 WHERE username = $1 OR '@' || username = $1 OR tg_peer_id::text = $1
`

type UpdateChannelContextParams struct {
	Username pgtype.Text `json:"username"`
	Context  pgtype.Text `json:"context"`
}

func (q *Queries) UpdateChannelContext(ctx context.Context, arg UpdateChannelContextParams) error {
	_, err := q.db.Exec(ctx, updateChannelContext, arg.Username, arg.Context)
	return err
}

const updateChannelLastMessageID = `-- name: UpdateChannelLastMessageID :exec
UPDATE channels SET last_tg_message_id = $2 WHERE id = $1
`

type UpdateChannelLastMessageIDParams struct {
	ID              pgtype.UUID `json:"id"`
	LastTgMessageID int64       `json:"last_tg_message_id"`
}

func (q *Queries) UpdateChannelLastMessageID(ctx context.Context, arg UpdateChannelLastMessageIDParams) error {
	_, err := q.db.Exec(ctx, updateChannelLastMessageID, arg.ID, arg.LastTgMessageID)
	return err
}

const updateChannelMetadata = `-- name: UpdateChannelMetadata :exec
UPDATE channels SET category = $2, tone = $3, update_freq = $4, relevance_threshold = $5, importance_threshold = $6 WHERE username = $1 OR '@' || username = $1 OR tg_peer_id::text = $1
`

type UpdateChannelMetadataParams struct {
	Username            pgtype.Text   `json:"username"`
	Category            pgtype.Text   `json:"category"`
	Tone                pgtype.Text   `json:"tone"`
	UpdateFreq          pgtype.Text   `json:"update_freq"`
	RelevanceThreshold  pgtype.Float4 `json:"relevance_threshold"`
	ImportanceThreshold pgtype.Float4 `json:"importance_threshold"`
}

func (q *Queries) UpdateChannelMetadata(ctx context.Context, arg UpdateChannelMetadataParams) error {
	_, err := q.db.Exec(ctx, updateChannelMetadata,
		arg.Username,
		arg.Category,
		arg.Tone,
		arg.UpdateFreq,
		arg.RelevanceThreshold,
		arg.ImportanceThreshold,
	)
	return err
}

const updateChannelRelevanceDelta = `-- name: UpdateChannelRelevanceDelta :exec
UPDATE channels
SET relevance_threshold_delta = $2,
    auto_relevance_enabled = $3
WHERE id = $1
`

type UpdateChannelRelevanceDeltaParams struct {
	ID                      pgtype.UUID   `json:"id"`
	RelevanceThresholdDelta pgtype.Float4 `json:"relevance_threshold_delta"`
	AutoRelevanceEnabled    pgtype.Bool   `json:"auto_relevance_enabled"`
}

func (q *Queries) UpdateChannelRelevanceDelta(ctx context.Context, arg UpdateChannelRelevanceDeltaParams) error {
	_, err := q.db.Exec(ctx, updateChannelRelevanceDelta, arg.ID, arg.RelevanceThresholdDelta, arg.AutoRelevanceEnabled)
	return err
}

const updateChannelWeight = `-- name: UpdateChannelWeight :one

UPDATE channels
SET importance_weight = $2,
    auto_weight_enabled = $3,
    weight_override = $4,
    weight_override_reason = $5,
    weight_updated_at = NOW(),
    weight_updated_by = $6
WHERE username = $1 OR '@' || username = $1 OR tg_peer_id::text = $1
RETURNING username, title
`

type UpdateChannelWeightParams struct {
	Username             pgtype.Text   `json:"username"`
	ImportanceWeight     pgtype.Float4 `json:"importance_weight"`
	AutoWeightEnabled    pgtype.Bool   `json:"auto_weight_enabled"`
	WeightOverride       pgtype.Bool   `json:"weight_override"`
	WeightOverrideReason pgtype.Text   `json:"weight_override_reason"`
	WeightUpdatedBy      pgtype.Int8   `json:"weight_updated_by"`
}

type UpdateChannelWeightRow struct {
	Username pgtype.Text `json:"username"`
	Title    pgtype.Text `json:"title"`
}

// Channel importance weight queries
func (q *Queries) UpdateChannelWeight(ctx context.Context, arg UpdateChannelWeightParams) (UpdateChannelWeightRow, error) {
	row := q.db.QueryRow(ctx, updateChannelWeight,
		arg.Username,
		arg.ImportanceWeight,
		arg.AutoWeightEnabled,
		arg.WeightOverride,
		arg.WeightOverrideReason,
		arg.WeightUpdatedBy,
	)
	var i UpdateChannelWeightRow
	err := row.Scan(&i.Username, &i.Title)
	return i, err
}

const updateDiscoveryChannelInfo = `-- name: UpdateDiscoveryChannelInfo :exec
UPDATE discovered_channels
SET title = COALESCE(NULLIF($1, ''), title),
    username = COALESCE(NULLIF($2, ''), username),
    description = COALESCE(NULLIF($3, ''), description),
    resolution_attempts = 0
WHERE id = $4
`

type UpdateDiscoveryChannelInfoParams struct {
	Title       interface{} `json:"title"`
	Username    interface{} `json:"username"`
	Description interface{} `json:"description"`
	ID          pgtype.UUID `json:"id"`
}

func (q *Queries) UpdateDiscoveryChannelInfo(ctx context.Context, arg UpdateDiscoveryChannelInfoParams) error {
	_, err := q.db.Exec(ctx, updateDiscoveryChannelInfo,
		arg.Title,
		arg.Username,
		arg.Description,
		arg.ID,
	)
	return err
}

const updateDiscoveryFromInvite = `-- name: UpdateDiscoveryFromInvite :exec
UPDATE discovered_channels
SET title = COALESCE(NULLIF($1, ''), title),
    username = COALESCE(NULLIF($2, ''), username),
    description = COALESCE(NULLIF($3, ''), description),
    tg_peer_id = COALESCE(NULLIF($4::bigint, 0::bigint), tg_peer_id),
    access_hash = COALESCE(NULLIF($5::bigint, 0::bigint), access_hash),
    resolution_attempts = 0
WHERE id = $6
`

type UpdateDiscoveryFromInviteParams struct {
	Title       interface{} `json:"title"`
	Username    interface{} `json:"username"`
	Description interface{} `json:"description"`
	TgPeerID    int64       `json:"tg_peer_id"`
	AccessHash  int64       `json:"access_hash"`
	ID          pgtype.UUID `json:"id"`
}

func (q *Queries) UpdateDiscoveryFromInvite(ctx context.Context, arg UpdateDiscoveryFromInviteParams) error {
	_, err := q.db.Exec(ctx, updateDiscoveryFromInvite,
		arg.Title,
		arg.Username,
		arg.Description,
		arg.TgPeerID,
		arg.AccessHash,
		arg.ID,
	)
	return err
}

const updateDiscoveryStatus = `-- name: UpdateDiscoveryStatus :exec
UPDATE discovered_channels
SET status = $2, status_changed_at = now(), status_changed_by = $3
WHERE id = $1
`

type UpdateDiscoveryStatusParams struct {
	ID              pgtype.UUID `json:"id"`
	Status          string      `json:"status"`
	StatusChangedBy pgtype.Int8 `json:"status_changed_by"`
}

func (q *Queries) UpdateDiscoveryStatus(ctx context.Context, arg UpdateDiscoveryStatusParams) error {
	_, err := q.db.Exec(ctx, updateDiscoveryStatus, arg.ID, arg.Status, arg.StatusChangedBy)
	return err
}

const updateDiscoveryStatusByUsername = `-- name: UpdateDiscoveryStatusByUsername :exec
WITH target AS (
    SELECT src.username AS t_username, src.tg_peer_id AS t_peer_id, src.invite_link AS t_invite
    FROM discovered_channels src
    WHERE lower(src.username) = lower($1) OR lower('@' || src.username) = lower($1)
    LIMIT 1
)
UPDATE discovered_channels dc
SET status = $2, status_changed_at = now(), status_changed_by = $3
FROM target
WHERE (dc.username != '' AND target.t_username != '' AND lower(dc.username) = lower(target.t_username))
   OR (dc.tg_peer_id = target.t_peer_id AND dc.tg_peer_id != 0 AND target.t_peer_id != 0)
   OR (dc.invite_link = target.t_invite AND dc.invite_link != '' AND target.t_invite != '')
`

type UpdateDiscoveryStatusByUsernameParams struct {
	Lower           string      `json:"lower"`
	Status          string      `json:"status"`
	StatusChangedBy pgtype.Int8 `json:"status_changed_by"`
}

// Rejects the target row AND any related rows that share peer_id or invite_link
// This prevents the same channel from reappearing via different discovery paths
func (q *Queries) UpdateDiscoveryStatusByUsername(ctx context.Context, arg UpdateDiscoveryStatusByUsernameParams) error {
	_, err := q.db.Exec(ctx, updateDiscoveryStatusByUsername, arg.Lower, arg.Status, arg.StatusChangedBy)
	return err
}

const upsertChannelQualityHistory = `-- name: UpsertChannelQualityHistory :exec
INSERT INTO channel_quality_history (
    channel_id,
    period_start,
    period_end,
    inclusion_rate,
    noise_rate,
    avg_importance,
    avg_relevance
)
VALUES ($1, $2, $3, $4, $5, $6, $7)
ON CONFLICT (channel_id, period_start, period_end) DO UPDATE SET
    inclusion_rate = EXCLUDED.inclusion_rate,
    noise_rate = EXCLUDED.noise_rate,
    avg_importance = EXCLUDED.avg_importance,
    avg_relevance = EXCLUDED.avg_relevance,
    updated_at = NOW()
`

type UpsertChannelQualityHistoryParams struct {
	ChannelID     pgtype.UUID `json:"channel_id"`
	PeriodStart   pgtype.Date `json:"period_start"`
	PeriodEnd     pgtype.Date `json:"period_end"`
	InclusionRate float64     `json:"inclusion_rate"`
	NoiseRate     float64     `json:"noise_rate"`
	AvgImportance float64     `json:"avg_importance"`
	AvgRelevance  float64     `json:"avg_relevance"`
}

func (q *Queries) UpsertChannelQualityHistory(ctx context.Context, arg UpsertChannelQualityHistoryParams) error {
	_, err := q.db.Exec(ctx, upsertChannelQualityHistory,
		arg.ChannelID,
		arg.PeriodStart,
		arg.PeriodEnd,
		arg.InclusionRate,
		arg.NoiseRate,
		arg.AvgImportance,
		arg.AvgRelevance,
	)
	return err
}

const upsertChannelRatingStats = `-- name: UpsertChannelRatingStats :exec

INSERT INTO channel_rating_stats (
    channel_id,
    period_start,
    period_end,
    weighted_good,
    weighted_bad,
    weighted_irrelevant,
    weighted_total,
    rating_count
)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
ON CONFLICT (channel_id, period_start, period_end) DO UPDATE SET
    weighted_good = EXCLUDED.weighted_good,
    weighted_bad = EXCLUDED.weighted_bad,
    weighted_irrelevant = EXCLUDED.weighted_irrelevant,
    weighted_total = EXCLUDED.weighted_total,
    rating_count = EXCLUDED.rating_count,
    updated_at = NOW()
`

type UpsertChannelRatingStatsParams struct {
	ChannelID          pgtype.UUID `json:"channel_id"`
	PeriodStart        pgtype.Date `json:"period_start"`
	PeriodEnd          pgtype.Date `json:"period_end"`
	WeightedGood       float64     `json:"weighted_good"`
	WeightedBad        float64     `json:"weighted_bad"`
	WeightedIrrelevant float64     `json:"weighted_irrelevant"`
	WeightedTotal      float64     `json:"weighted_total"`
	RatingCount        int32       `json:"rating_count"`
}

// Channel Rating Stats queries
func (q *Queries) UpsertChannelRatingStats(ctx context.Context, arg UpsertChannelRatingStatsParams) error {
	_, err := q.db.Exec(ctx, upsertChannelRatingStats,
		arg.ChannelID,
		arg.PeriodStart,
		arg.PeriodEnd,
		arg.WeightedGood,
		arg.WeightedBad,
		arg.WeightedIrrelevant,
		arg.WeightedTotal,
		arg.RatingCount,
	)
	return err
}

const upsertChannelStats = `-- name: UpsertChannelStats :exec

INSERT INTO channel_stats (channel_id, period_start, period_end, messages_received, items_created, items_digested, avg_importance, avg_relevance)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
ON CONFLICT (channel_id, period_start, period_end) DO UPDATE SET
    messages_received = channel_stats.messages_received + EXCLUDED.messages_received,
    items_created = channel_stats.items_created + EXCLUDED.items_created,
    items_digested = channel_stats.items_digested + EXCLUDED.items_digested,
    avg_importance = EXCLUDED.avg_importance,
    avg_relevance = EXCLUDED.avg_relevance,
    updated_at = NOW()
`

type UpsertChannelStatsParams struct {
	ChannelID        pgtype.UUID   `json:"channel_id"`
	PeriodStart      pgtype.Date   `json:"period_start"`
	PeriodEnd        pgtype.Date   `json:"period_end"`
	MessagesReceived pgtype.Int4   `json:"messages_received"`
	ItemsCreated     pgtype.Int4   `json:"items_created"`
	ItemsDigested    pgtype.Int4   `json:"items_digested"`
	AvgImportance    pgtype.Float8 `json:"avg_importance"`
	AvgRelevance     pgtype.Float8 `json:"avg_relevance"`
}

// Channel stats queries
func (q *Queries) UpsertChannelStats(ctx context.Context, arg UpsertChannelStatsParams) error {
	_, err := q.db.Exec(ctx, upsertChannelStats,
		arg.ChannelID,
		arg.PeriodStart,
		arg.PeriodEnd,
		arg.MessagesReceived,
		arg.ItemsCreated,
		arg.ItemsDigested,
		arg.AvgImportance,
		arg.AvgRelevance,
	)
	return err
}

const upsertClusterSummaryCache = `-- name: UpsertClusterSummaryCache :exec
INSERT INTO cluster_summary_cache (
    digest_language,
    cluster_fingerprint,
    item_ids,
    summary,
    created_at,
    updated_at
) VALUES ($1, $2, $3, $4, now(), now())
ON CONFLICT (digest_language, cluster_fingerprint) DO UPDATE SET
    item_ids = EXCLUDED.item_ids,
    summary = EXCLUDED.summary,
    updated_at = now()
`

type UpsertClusterSummaryCacheParams struct {
	DigestLanguage     string `json:"digest_language"`
	ClusterFingerprint string `json:"cluster_fingerprint"`
	ItemIds            []byte `json:"item_ids"`
	Summary            string `json:"summary"`
}

func (q *Queries) UpsertClusterSummaryCache(ctx context.Context, arg UpsertClusterSummaryCacheParams) error {
	_, err := q.db.Exec(ctx, upsertClusterSummaryCache,
		arg.DigestLanguage,
		arg.ClusterFingerprint,
		arg.ItemIds,
		arg.Summary,
	)
	return err
}

const upsertDiscoveredChannelByInvite = `-- name: UpsertDiscoveredChannelByInvite :exec
INSERT INTO discovered_channels (invite_link, source_type, discovered_from_channel_id, max_views, max_forwards, engagement_score)
VALUES ($1, $2, $3, $4, $5, ln(1 + COALESCE($4, 0)) * 0.3 + ln(1 + COALESCE($5, 0)) * 0.5 + ln(2) * 0.2)
ON CONFLICT (invite_link) WHERE invite_link IS NOT NULL AND invite_link != ''
DO UPDATE SET
    discovery_count = discovered_channels.discovery_count + 1,
    last_seen_at = now(),
    max_views = GREATEST(discovered_channels.max_views, COALESCE($4, 0)),
    max_forwards = GREATEST(discovered_channels.max_forwards, COALESCE($5, 0)),
    engagement_score = ln(1 + GREATEST(discovered_channels.max_views, COALESCE($4, 0))) * 0.3 +
                       ln(1 + GREATEST(discovered_channels.max_forwards, COALESCE($5, 0))) * 0.5 +
                       ln(1 + discovered_channels.discovery_count + 1) * 0.2
`

type UpsertDiscoveredChannelByInviteParams struct {
	InviteLink              pgtype.Text `json:"invite_link"`
	SourceType              string      `json:"source_type"`
	DiscoveredFromChannelID pgtype.UUID `json:"discovered_from_channel_id"`
	MaxViews                pgtype.Int4 `json:"max_views"`
	MaxForwards             pgtype.Int4 `json:"max_forwards"`
}

func (q *Queries) UpsertDiscoveredChannelByInvite(ctx context.Context, arg UpsertDiscoveredChannelByInviteParams) error {
	_, err := q.db.Exec(ctx, upsertDiscoveredChannelByInvite,
		arg.InviteLink,
		arg.SourceType,
		arg.DiscoveredFromChannelID,
		arg.MaxViews,
		arg.MaxForwards,
	)
	return err
}

const upsertDiscoveredChannelByPeerID = `-- name: UpsertDiscoveredChannelByPeerID :exec
INSERT INTO discovered_channels (tg_peer_id, title, source_type, discovered_from_channel_id, max_views, max_forwards, engagement_score, access_hash)
VALUES ($1, $2, $3, $4, $5, $6, ln(1 + COALESCE($5, 0)) * 0.3 + ln(1 + COALESCE($6, 0)) * 0.5 + ln(2) * 0.2, $7)
ON CONFLICT (tg_peer_id) WHERE tg_peer_id != 0
DO UPDATE SET
    discovery_count = discovered_channels.discovery_count + 1,
    last_seen_at = now(),
    title = COALESCE(NULLIF($2, ''), discovered_channels.title),
    max_views = GREATEST(discovered_channels.max_views, COALESCE($5, 0)),
    max_forwards = GREATEST(discovered_channels.max_forwards, COALESCE($6, 0)),
    engagement_score = ln(1 + GREATEST(discovered_channels.max_views, COALESCE($5, 0))) * 0.3 +
                       ln(1 + GREATEST(discovered_channels.max_forwards, COALESCE($6, 0))) * 0.5 +
                       ln(1 + discovered_channels.discovery_count + 1) * 0.2,
    access_hash = COALESCE(NULLIF($7, 0), discovered_channels.access_hash)
`

type UpsertDiscoveredChannelByPeerIDParams struct {
	TgPeerID                pgtype.Int8 `json:"tg_peer_id"`
	Title                   pgtype.Text `json:"title"`
	SourceType              string      `json:"source_type"`
	DiscoveredFromChannelID pgtype.UUID `json:"discovered_from_channel_id"`
	MaxViews                pgtype.Int4 `json:"max_views"`
	MaxForwards             pgtype.Int4 `json:"max_forwards"`
	AccessHash              pgtype.Int8 `json:"access_hash"`
}

func (q *Queries) UpsertDiscoveredChannelByPeerID(ctx context.Context, arg UpsertDiscoveredChannelByPeerIDParams) error {
	_, err := q.db.Exec(ctx, upsertDiscoveredChannelByPeerID,
		arg.TgPeerID,
		arg.Title,
		arg.SourceType,
		arg.DiscoveredFromChannelID,
		arg.MaxViews,
		arg.MaxForwards,
		arg.AccessHash,
	)
	return err
}

const upsertDiscoveredChannelByUsername = `-- name: UpsertDiscoveredChannelByUsername :exec

INSERT INTO discovered_channels (username, title, source_type, discovered_from_channel_id, max_views, max_forwards, engagement_score)
VALUES ($1, $2, $3, $4, $5, $6, ln(1 + COALESCE($5, 0)) * 0.3 + ln(1 + COALESCE($6, 0)) * 0.5 + ln(2) * 0.2)
ON CONFLICT (username) WHERE username IS NOT NULL AND username != ''
DO UPDATE SET
    discovery_count = discovered_channels.discovery_count + 1,
    last_seen_at = now(),
    title = COALESCE(NULLIF($2, ''), discovered_channels.title),
    max_views = GREATEST(discovered_channels.max_views, COALESCE($5, 0)),
    max_forwards = GREATEST(discovered_channels.max_forwards, COALESCE($6, 0)),
    engagement_score = ln(1 + GREATEST(discovered_channels.max_views, COALESCE($5, 0))) * 0.3 +
                       ln(1 + GREATEST(discovered_channels.max_forwards, COALESCE($6, 0))) * 0.5 +
                       ln(1 + discovered_channels.discovery_count + 1) * 0.2
`

type UpsertDiscoveredChannelByUsernameParams struct {
	Username                pgtype.Text `json:"username"`
	Title                   pgtype.Text `json:"title"`
	SourceType              string      `json:"source_type"`
	DiscoveredFromChannelID pgtype.UUID `json:"discovered_from_channel_id"`
	MaxViews                pgtype.Int4 `json:"max_views"`
	MaxForwards             pgtype.Int4 `json:"max_forwards"`
}

// Channel Discovery queries
func (q *Queries) UpsertDiscoveredChannelByUsername(ctx context.Context, arg UpsertDiscoveredChannelByUsernameParams) error {
	_, err := q.db.Exec(ctx, upsertDiscoveredChannelByUsername,
		arg.Username,
		arg.Title,
		arg.SourceType,
		arg.DiscoveredFromChannelID,
		arg.MaxViews,
		arg.MaxForwards,
	)
	return err
}

const upsertGlobalRatingStats = `-- name: UpsertGlobalRatingStats :exec
INSERT INTO global_rating_stats (
    period_start,
    period_end,
    weighted_good,
    weighted_bad,
    weighted_irrelevant,
    weighted_total,
    rating_count
)
VALUES ($1, $2, $3, $4, $5, $6, $7)
ON CONFLICT (period_start, period_end) DO UPDATE SET
    weighted_good = EXCLUDED.weighted_good,
    weighted_bad = EXCLUDED.weighted_bad,
    weighted_irrelevant = EXCLUDED.weighted_irrelevant,
    weighted_total = EXCLUDED.weighted_total,
    rating_count = EXCLUDED.rating_count,
    updated_at = NOW()
`

type UpsertGlobalRatingStatsParams struct {
	PeriodStart        pgtype.Date `json:"period_start"`
	PeriodEnd          pgtype.Date `json:"period_end"`
	WeightedGood       float64     `json:"weighted_good"`
	WeightedBad        float64     `json:"weighted_bad"`
	WeightedIrrelevant float64     `json:"weighted_irrelevant"`
	WeightedTotal      float64     `json:"weighted_total"`
	RatingCount        int32       `json:"rating_count"`
}

func (q *Queries) UpsertGlobalRatingStats(ctx context.Context, arg UpsertGlobalRatingStatsParams) error {
	_, err := q.db.Exec(ctx, upsertGlobalRatingStats,
		arg.PeriodStart,
		arg.PeriodEnd,
		arg.WeightedGood,
		arg.WeightedBad,
		arg.WeightedIrrelevant,
		arg.WeightedTotal,
		arg.RatingCount,
	)
	return err
}

const upsertSummaryCache = `-- name: UpsertSummaryCache :exec
INSERT INTO summary_cache (
    canonical_hash,
    digest_language,
    summary,
    topic,
    language,
    relevance_score,
    importance_score,
    created_at,
    updated_at
) VALUES ($1, $2, $3, $4, $5, $6, $7, now(), now())
ON CONFLICT (canonical_hash, digest_language) DO UPDATE SET
    summary = EXCLUDED.summary,
    topic = EXCLUDED.topic,
    language = EXCLUDED.language,
    relevance_score = EXCLUDED.relevance_score,
    importance_score = EXCLUDED.importance_score,
    updated_at = now()
`

type UpsertSummaryCacheParams struct {
	CanonicalHash   string      `json:"canonical_hash"`
	DigestLanguage  string      `json:"digest_language"`
	Summary         string      `json:"summary"`
	Topic           pgtype.Text `json:"topic"`
	Language        pgtype.Text `json:"language"`
	RelevanceScore  float32     `json:"relevance_score"`
	ImportanceScore float32     `json:"importance_score"`
}

func (q *Queries) UpsertSummaryCache(ctx context.Context, arg UpsertSummaryCacheParams) error {
	_, err := q.db.Exec(ctx, upsertSummaryCache,
		arg.CanonicalHash,
		arg.DigestLanguage,
		arg.Summary,
		arg.Topic,
		arg.Language,
		arg.RelevanceScore,
		arg.ImportanceScore,
	)
	return err
}
